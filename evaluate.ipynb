{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613ebee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from cliffs_delta import cliffs_delta as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6511d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(x, y):\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    nx, ny = len(x), len(y)\n",
    "    vx, vy = np.var(x, ddof=1), np.var(y, ddof=1)\n",
    "    sp = np.sqrt(((nx-1)*vx + (ny-1)*vy) / (nx + ny - 2))\n",
    "    return (np.mean(x) - np.mean(y)) / sp\n",
    "\n",
    "def get_corr_stats(df_analysis, binary=False, feats=[\"surprisal\"], score_col=\"score\", binary_col='labels'):\n",
    "\n",
    "    pearson_coef = []\n",
    "    pearson_p = []\n",
    "    spearman_coef = []\n",
    "    spearman_p = []\n",
    "    kendall_coef = []\n",
    "    kendall_p = []\n",
    "    \n",
    "    rank_biserial_r = []\n",
    "    mw_u = []\n",
    "    mw_p = []\n",
    "    cohens_ds = []\n",
    "    auc_s = []\n",
    "    cliffs_delta = []\n",
    "    cliffs_size = []\n",
    "\n",
    "    if not binary:\n",
    "        threshold = 0.5\n",
    "        y_true = np.array([1]*len(df_analysis[df_analysis[score_col]>=threshold]) + [0]*len(df_analysis[df_analysis[score_col]<threshold]))\n",
    "    else:\n",
    "        y_true = np.array([1]*len(df_analysis[df_analysis[binary_col]=='novel']) + [0]*len(df_analysis[df_analysis[binary_col]==\"conventional\"]))\n",
    "\n",
    "    for col in feats:\n",
    "\n",
    "        if not binary:\n",
    "        \n",
    "            # 1. Pearson\n",
    "            pearson_c, pearson_pv = pearsonr(df_analysis[score_col], df_analysis[col])\n",
    "            pearson_coef.append(pearson_c)\n",
    "            pearson_p.append(pearson_pv)\n",
    "\n",
    "            # 2. Spearman\n",
    "            spearman_c, spearman_pv = spearmanr(df_analysis[score_col], df_analysis[col])\n",
    "            spearman_coef.append(spearman_c)\n",
    "            spearman_p.append(spearman_pv)\n",
    "\n",
    "            # 3. Kendall\n",
    "            kendall_c, kendall_pv = kendalltau(df_analysis[score_col], df_analysis[col])\n",
    "            kendall_coef.append(kendall_c)\n",
    "            kendall_p.append(kendall_pv)\n",
    "\n",
    "            # 4. Mann-Whitney U\n",
    "            mw_u_stat, mw_pv = mannwhitneyu(df_analysis[df_analysis[score_col]>=threshold][col],\n",
    "                                                df_analysis[df_analysis[score_col]<threshold][col])\n",
    "            mw_u.append(mw_u_stat)\n",
    "            mw_p.append(mw_pv)\n",
    "\n",
    "            # 5. Rank-biserial correlation\n",
    "            n1, n2 = len(df_analysis[df_analysis[score_col]>=threshold]), len(df_analysis[df_analysis[score_col]<threshold])\n",
    "            rank_biserial = 2*mw_u_stat/(n1*n2) - 1\n",
    "            rank_biserial_r.append(rank_biserial)\n",
    "\n",
    "            # 6. Cohen's d\n",
    "            d = cohens_d(df_analysis[df_analysis[score_col]>=threshold][col], df_analysis[df_analysis[score_col]<threshold][col])\n",
    "            cohens_ds.append(d)\n",
    "\n",
    "            # 7. AUC\n",
    "            surpr_all = np.concatenate([df_analysis[df_analysis[score_col]>=threshold][col], df_analysis[df_analysis[score_col]<threshold][col]])\n",
    "            auc = roc_auc_score(y_true, surpr_all)   # use +surpr_all if higher surprisal => Positive\n",
    "            auc_s.append(auc)\n",
    "\n",
    "            # 8. Cliff's delta\n",
    "            d, size = cd(df_analysis[df_analysis[score_col]>=threshold][col], df_analysis[df_analysis[score_col]<threshold][col])\n",
    "            cliffs_delta.append(d)\n",
    "            cliffs_size.append(size)\n",
    "        else:\n",
    "\n",
    "            # 4. Mann-Whitney U\n",
    "            mw_u_stat, mw_pv = mannwhitneyu(df_analysis[df_analysis[binary_col]=='novel'][col],\n",
    "                                                df_analysis[df_analysis[binary_col]==\"conventional\"][col])\n",
    "            mw_u.append(mw_u_stat)\n",
    "            mw_p.append(mw_pv)\n",
    "            \n",
    "            # 5. Rank-biserial correlation\n",
    "            n1, n2 = len(df_analysis[df_analysis[binary_col]=='novel']), len(df_analysis[df_analysis[binary_col]==\"conventional\"])\n",
    "            rank_biserial = 2*mw_u_stat/(n1*n2) - 1\n",
    "            rank_biserial_r.append(rank_biserial)\n",
    "            \n",
    "            # 6. Cohen's d\n",
    "            d = cohens_d(df_analysis[df_analysis[binary_col]=='novel'][col], df_analysis[df_analysis[binary_col]==\"conventional\"][col])\n",
    "            cohens_ds.append(d)\n",
    "            \n",
    "            # 7. AUC\n",
    "            surpr_all = np.concatenate([df_analysis[df_analysis[binary_col]=='novel'][col], df_analysis[df_analysis[binary_col]==\"conventional\"][col]])\n",
    "            auc = roc_auc_score(y_true, surpr_all)   # use +surpr_all if higher surprisal => Positive\n",
    "            auc_s.append(auc)\n",
    "            \n",
    "            # 8. Cliff's delta\n",
    "            d, size = cd(df_analysis[df_analysis[binary_col]=='novel'][col], df_analysis[df_analysis[binary_col]==\"conventional\"][col])\n",
    "            cliffs_delta.append(d)\n",
    "            cliffs_size.append(size)\n",
    "            \n",
    "\n",
    "    if not binary:        \n",
    "        df_stats = pd.DataFrame({\n",
    "            \"feature\": feats,\n",
    "            \"pearson_coef\": pearson_coef,\n",
    "            \"pearson_p\": pearson_p,\n",
    "            \"spearman_coef\": spearman_coef,\n",
    "            \"spearman_p\": spearman_p,\n",
    "            \"rank_biserial_r\": rank_biserial_r,\n",
    "            \"auc\": auc_s,\n",
    "            \"mw_p\": mw_p,\n",
    "            \"cohens_d\": cohens_ds,\n",
    "            \"cliffs_delta\": cliffs_delta,\n",
    "            \"cliffs_size\": cliffs_size\n",
    "        })\n",
    "    else:\n",
    "        df_stats = pd.DataFrame({\n",
    "            \"feature\": feats,\n",
    "            \"rank_biserial_r\": rank_biserial_r,\n",
    "            \"auc\": auc_s,\n",
    "            \"mw_p\": mw_p,\n",
    "            \"cohens_d\": cohens_ds,\n",
    "            \"cliffs_delta\": cliffs_delta,\n",
    "            \"cliffs_size\": cliffs_size\n",
    "        })\n",
    "\n",
    "    return df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ed3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467aa59c",
   "metadata": {},
   "source": [
    "# VUA-ratings results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "599e7cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vua-metanov_surprisal_meta-llama_Llama-3.2-3B_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_openai-community_gpt2_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_meta-llama_Llama-3.1-8B-Instruct_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_Qwen_Qwen2.5-7B_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_openai-community_gpt2-xl_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_meta-llama_Llama-3.2-3B-Instruct_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_meta-llama_Llama-3.1-8B_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_Qwen_Qwen2.5-14B_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_openai-community_gpt2-medium_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_meta-llama_Llama-3.2-1B_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_Qwen_Qwen2.5-0.5B-Instruct_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_Qwen_Qwen2.5-0.5B_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_openai-community_gpt2-large_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_meta-llama_Llama-3.2-1B-Instruct_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_Qwen_Qwen2.5-7B-Instruct_cloze_pimentel.parquet...\n",
      "Loading vua-metanov_surprisal_Qwen_Qwen2.5-14B-Instruct_cloze_pimentel.parquet...\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "models_ids = []\n",
    "for f in os.listdir(\"results\"):\n",
    "    if f.endswith(\".parquet\") and \"vua\" in f:\n",
    "        print(f\"Loading {f}...\")\n",
    "        df_part = pd.read_parquet(os.path.join(\"results\", f))\n",
    "        all_results.append(df_part)\n",
    "        models_ids.append(f.split(\"_\")[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075f6e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Llama-3.2-3B',\n",
       "  'gpt2',\n",
       "  'Llama-3.1-8B-Instruct',\n",
       "  'Qwen2.5-7B',\n",
       "  'gpt2-xl',\n",
       "  'Llama-3.2-3B-Instruct',\n",
       "  'Llama-3.1-8B',\n",
       "  'Qwen2.5-14B',\n",
       "  'gpt2-medium',\n",
       "  'Llama-3.2-1B',\n",
       "  'Qwen2.5-0.5B-Instruct',\n",
       "  'Qwen2.5-0.5B',\n",
       "  'gpt2-large',\n",
       "  'Llama-3.2-1B-Instruct',\n",
       "  'Qwen2.5-7B-Instruct',\n",
       "  'Qwen2.5-14B-Instruct'],\n",
       " 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ids, len(models_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b066ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16202 entries, 0 to 16201\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   document_id             16202 non-null  object\n",
      " 1   sentence_id             16202 non-null  object\n",
      " 2   sentence                16202 non-null  object\n",
      " 3   words_list              16202 non-null  object\n",
      " 4   offsets                 16202 non-null  object\n",
      " 5   vua_metaphor_labels     16202 non-null  object\n",
      " 6   do_dinh_scores          16202 non-null  object\n",
      " 7   reimann_novelty_labels  16202 non-null  object\n",
      " 8   genre                   16202 non-null  object\n",
      " 9   subtoken_ids            16202 non-null  object\n",
      " 10  subtoken_strs           16202 non-null  object\n",
      " 11  surprisal_buggy         16202 non-null  object\n",
      " 12  surprisal_fixed         16202 non-null  object\n",
      " 13  subtoken_ids_cloze      16202 non-null  object\n",
      " 14  subtoken_strs_cloze     16202 non-null  object\n",
      " 15  surprisal_buggy_cloze   16202 non-null  object\n",
      " 16  surprisal_fixed_cloze   16202 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "all_results[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1d639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame()\n",
    "for k, df in enumerate(all_results):\n",
    "    do_dinh_scores = []\n",
    "    surp_buggy = []\n",
    "    surp_fixed = []\n",
    "    surp_buggy_cloze = []\n",
    "    surp_fixed_cloze = []\n",
    "    for i, row in df.iterrows():\n",
    "        for j, label in enumerate(row['vua_metaphor_labels']):\n",
    "            if label == True:\n",
    "                scs = row['do_dinh_scores'][j]\n",
    "                scs = max([float(s) for s in scs.split(\",\")])\n",
    "                if scs > -1:\n",
    "                    do_dinh_scores.append(scs)\n",
    "                    surp_buggy.append(row['surprisal_buggy'][j].item())\n",
    "                    surp_fixed.append(row['surprisal_fixed'][j].item())\n",
    "                    surp_buggy_cloze.append(row['surprisal_buggy_cloze'][j].item())\n",
    "                    surp_fixed_cloze.append(row['surprisal_fixed_cloze'][j].item())\n",
    "        \n",
    "                    \n",
    "    df_analysis['score'] = do_dinh_scores\n",
    "    df_analysis[f\"surprisal_buggy_{models_ids[k]}\"] = surp_buggy\n",
    "    df_analysis[f\"surprisal_fixed_{models_ids[k]}\"] = surp_fixed\n",
    "    df_analysis[f\"surprisal_buggy_cloze_{models_ids[k]}\"] = surp_buggy_cloze\n",
    "    df_analysis[f\"surprisal_fixed_cloze_{models_ids[k]}\"] = surp_fixed_cloze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f288be9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15155 entries, 0 to 15154\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   score                                        15155 non-null  float64\n",
      " 1   surprisal_buggy_Llama-3.2-3B                 15155 non-null  float64\n",
      " 2   surprisal_fixed_Llama-3.2-3B                 15155 non-null  float64\n",
      " 3   surprisal_buggy_cloze_Llama-3.2-3B           15155 non-null  float64\n",
      " 4   surprisal_fixed_cloze_Llama-3.2-3B           15155 non-null  float64\n",
      " 5   surprisal_buggy_gpt2                         15155 non-null  float64\n",
      " 6   surprisal_fixed_gpt2                         15155 non-null  float64\n",
      " 7   surprisal_buggy_cloze_gpt2                   15155 non-null  float64\n",
      " 8   surprisal_fixed_cloze_gpt2                   15155 non-null  float64\n",
      " 9   surprisal_buggy_Llama-3.1-8B-Instruct        15155 non-null  float64\n",
      " 10  surprisal_fixed_Llama-3.1-8B-Instruct        15155 non-null  float64\n",
      " 11  surprisal_buggy_cloze_Llama-3.1-8B-Instruct  15155 non-null  float64\n",
      " 12  surprisal_fixed_cloze_Llama-3.1-8B-Instruct  15155 non-null  float64\n",
      " 13  surprisal_buggy_Qwen2.5-7B                   15155 non-null  float64\n",
      " 14  surprisal_fixed_Qwen2.5-7B                   15155 non-null  float64\n",
      " 15  surprisal_buggy_cloze_Qwen2.5-7B             15155 non-null  float64\n",
      " 16  surprisal_fixed_cloze_Qwen2.5-7B             15155 non-null  float64\n",
      " 17  surprisal_buggy_gpt2-xl                      15155 non-null  float64\n",
      " 18  surprisal_fixed_gpt2-xl                      15155 non-null  float64\n",
      " 19  surprisal_buggy_cloze_gpt2-xl                15155 non-null  float64\n",
      " 20  surprisal_fixed_cloze_gpt2-xl                15155 non-null  float64\n",
      " 21  surprisal_buggy_Llama-3.2-3B-Instruct        15155 non-null  float64\n",
      " 22  surprisal_fixed_Llama-3.2-3B-Instruct        15155 non-null  float64\n",
      " 23  surprisal_buggy_cloze_Llama-3.2-3B-Instruct  15155 non-null  float64\n",
      " 24  surprisal_fixed_cloze_Llama-3.2-3B-Instruct  15155 non-null  float64\n",
      " 25  surprisal_buggy_Llama-3.1-8B                 15155 non-null  float64\n",
      " 26  surprisal_fixed_Llama-3.1-8B                 15155 non-null  float64\n",
      " 27  surprisal_buggy_cloze_Llama-3.1-8B           15155 non-null  float64\n",
      " 28  surprisal_fixed_cloze_Llama-3.1-8B           15155 non-null  float64\n",
      " 29  surprisal_buggy_Qwen2.5-14B                  15155 non-null  float64\n",
      " 30  surprisal_fixed_Qwen2.5-14B                  15155 non-null  float64\n",
      " 31  surprisal_buggy_cloze_Qwen2.5-14B            15155 non-null  float64\n",
      " 32  surprisal_fixed_cloze_Qwen2.5-14B            15155 non-null  float64\n",
      " 33  surprisal_buggy_gpt2-medium                  15155 non-null  float64\n",
      " 34  surprisal_fixed_gpt2-medium                  15155 non-null  float64\n",
      " 35  surprisal_buggy_cloze_gpt2-medium            15155 non-null  float64\n",
      " 36  surprisal_fixed_cloze_gpt2-medium            15155 non-null  float64\n",
      " 37  surprisal_buggy_Llama-3.2-1B                 15155 non-null  float64\n",
      " 38  surprisal_fixed_Llama-3.2-1B                 15155 non-null  float64\n",
      " 39  surprisal_buggy_cloze_Llama-3.2-1B           15155 non-null  float64\n",
      " 40  surprisal_fixed_cloze_Llama-3.2-1B           15155 non-null  float64\n",
      " 41  surprisal_buggy_Qwen2.5-0.5B-Instruct        15155 non-null  float64\n",
      " 42  surprisal_fixed_Qwen2.5-0.5B-Instruct        15155 non-null  float64\n",
      " 43  surprisal_buggy_cloze_Qwen2.5-0.5B-Instruct  15155 non-null  float64\n",
      " 44  surprisal_fixed_cloze_Qwen2.5-0.5B-Instruct  15155 non-null  float64\n",
      " 45  surprisal_buggy_Qwen2.5-0.5B                 15155 non-null  float64\n",
      " 46  surprisal_fixed_Qwen2.5-0.5B                 15155 non-null  float64\n",
      " 47  surprisal_buggy_cloze_Qwen2.5-0.5B           15155 non-null  float64\n",
      " 48  surprisal_fixed_cloze_Qwen2.5-0.5B           15155 non-null  float64\n",
      " 49  surprisal_buggy_gpt2-large                   15155 non-null  float64\n",
      " 50  surprisal_fixed_gpt2-large                   15155 non-null  float64\n",
      " 51  surprisal_buggy_cloze_gpt2-large             15155 non-null  float64\n",
      " 52  surprisal_fixed_cloze_gpt2-large             15155 non-null  float64\n",
      " 53  surprisal_buggy_Llama-3.2-1B-Instruct        15155 non-null  float64\n",
      " 54  surprisal_fixed_Llama-3.2-1B-Instruct        15155 non-null  float64\n",
      " 55  surprisal_buggy_cloze_Llama-3.2-1B-Instruct  15155 non-null  float64\n",
      " 56  surprisal_fixed_cloze_Llama-3.2-1B-Instruct  15155 non-null  float64\n",
      " 57  surprisal_buggy_Qwen2.5-7B-Instruct          15155 non-null  float64\n",
      " 58  surprisal_fixed_Qwen2.5-7B-Instruct          15155 non-null  float64\n",
      " 59  surprisal_buggy_cloze_Qwen2.5-7B-Instruct    15155 non-null  float64\n",
      " 60  surprisal_fixed_cloze_Qwen2.5-7B-Instruct    15155 non-null  float64\n",
      " 61  surprisal_buggy_Qwen2.5-14B-Instruct         15155 non-null  float64\n",
      " 62  surprisal_fixed_Qwen2.5-14B-Instruct         15155 non-null  float64\n",
      " 63  surprisal_buggy_cloze_Qwen2.5-14B-Instruct   15155 non-null  float64\n",
      " 64  surprisal_fixed_cloze_Qwen2.5-14B-Instruct   15155 non-null  float64\n",
      "dtypes: float64(65)\n",
      "memory usage: 7.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef83bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>pearson_coef</th>\n",
       "      <th>pearson_p</th>\n",
       "      <th>spearman_coef</th>\n",
       "      <th>spearman_p</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprisal_buggy_Llama-3.2-3B</td>\n",
       "      <td>0.320215</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.301315</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.491383</td>\n",
       "      <td>0.745691</td>\n",
       "      <td>2.973274e-56</td>\n",
       "      <td>1.004674</td>\n",
       "      <td>0.491383</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprisal_buggy_gpt2</td>\n",
       "      <td>0.412258</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.409555</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.630008</td>\n",
       "      <td>0.815004</td>\n",
       "      <td>2.839013e-91</td>\n",
       "      <td>1.358969</td>\n",
       "      <td>0.630008</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprisal_buggy_Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.307090</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.288649</td>\n",
       "      <td>1.260471e-288</td>\n",
       "      <td>0.495135</td>\n",
       "      <td>0.747568</td>\n",
       "      <td>4.350308e-57</td>\n",
       "      <td>1.020528</td>\n",
       "      <td>0.495135</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisal_buggy_Qwen2.5-7B</td>\n",
       "      <td>0.328355</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.309615</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.493323</td>\n",
       "      <td>0.746662</td>\n",
       "      <td>1.102671e-56</td>\n",
       "      <td>1.015082</td>\n",
       "      <td>0.493323</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprisal_buggy_gpt2-xl</td>\n",
       "      <td>0.366349</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.355127</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.557553</td>\n",
       "      <td>0.778777</td>\n",
       "      <td>6.767423e-72</td>\n",
       "      <td>1.171678</td>\n",
       "      <td>0.557553</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-0.5B</td>\n",
       "      <td>0.392178</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.384340</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.576742</td>\n",
       "      <td>0.788371</td>\n",
       "      <td>8.463839e-77</td>\n",
       "      <td>1.304927</td>\n",
       "      <td>0.576742</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.455469</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.459231</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.647690</td>\n",
       "      <td>0.823845</td>\n",
       "      <td>2.329887e-96</td>\n",
       "      <td>1.400866</td>\n",
       "      <td>0.647690</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>surprisal_fixed_cloze_Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.349787</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.333738</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.533265</td>\n",
       "      <td>0.766632</td>\n",
       "      <td>6.308102e-66</td>\n",
       "      <td>1.191905</td>\n",
       "      <td>0.533265</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.232095</td>\n",
       "      <td>1.752780e-184</td>\n",
       "      <td>0.215450</td>\n",
       "      <td>1.207894e-158</td>\n",
       "      <td>0.416679</td>\n",
       "      <td>0.708339</td>\n",
       "      <td>6.015453e-41</td>\n",
       "      <td>0.895953</td>\n",
       "      <td>0.416679</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.204478</td>\n",
       "      <td>9.210363e-143</td>\n",
       "      <td>0.184066</td>\n",
       "      <td>1.358459e-115</td>\n",
       "      <td>0.387422</td>\n",
       "      <td>0.693711</td>\n",
       "      <td>1.241765e-35</td>\n",
       "      <td>0.867633</td>\n",
       "      <td>0.387422</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feature  pearson_coef      pearson_p  \\\n",
       "0                  surprisal_buggy_Llama-3.2-3B      0.320215   0.000000e+00   \n",
       "1                          surprisal_buggy_gpt2      0.412258   0.000000e+00   \n",
       "2         surprisal_buggy_Llama-3.1-8B-Instruct      0.307090   0.000000e+00   \n",
       "3                    surprisal_buggy_Qwen2.5-7B      0.328355   0.000000e+00   \n",
       "4                       surprisal_buggy_gpt2-xl      0.366349   0.000000e+00   \n",
       "..                                          ...           ...            ...   \n",
       "59           surprisal_fixed_cloze_Qwen2.5-0.5B      0.392178   0.000000e+00   \n",
       "60             surprisal_fixed_cloze_gpt2-large      0.455469   0.000000e+00   \n",
       "61  surprisal_fixed_cloze_Llama-3.2-1B-Instruct      0.349787   0.000000e+00   \n",
       "62    surprisal_fixed_cloze_Qwen2.5-7B-Instruct      0.232095  1.752780e-184   \n",
       "63   surprisal_fixed_cloze_Qwen2.5-14B-Instruct      0.204478  9.210363e-143   \n",
       "\n",
       "    spearman_coef     spearman_p  rank_biserial_r       auc          mw_p  \\\n",
       "0        0.301315   0.000000e+00         0.491383  0.745691  2.973274e-56   \n",
       "1        0.409555   0.000000e+00         0.630008  0.815004  2.839013e-91   \n",
       "2        0.288649  1.260471e-288         0.495135  0.747568  4.350308e-57   \n",
       "3        0.309615   0.000000e+00         0.493323  0.746662  1.102671e-56   \n",
       "4        0.355127   0.000000e+00         0.557553  0.778777  6.767423e-72   \n",
       "..            ...            ...              ...       ...           ...   \n",
       "59       0.384340   0.000000e+00         0.576742  0.788371  8.463839e-77   \n",
       "60       0.459231   0.000000e+00         0.647690  0.823845  2.329887e-96   \n",
       "61       0.333738   0.000000e+00         0.533265  0.766632  6.308102e-66   \n",
       "62       0.215450  1.207894e-158         0.416679  0.708339  6.015453e-41   \n",
       "63       0.184066  1.358459e-115         0.387422  0.693711  1.241765e-35   \n",
       "\n",
       "    cohens_d  cliffs_delta cliffs_size  \n",
       "0   1.004674      0.491383       large  \n",
       "1   1.358969      0.630008       large  \n",
       "2   1.020528      0.495135       large  \n",
       "3   1.015082      0.493323       large  \n",
       "4   1.171678      0.557553       large  \n",
       "..       ...           ...         ...  \n",
       "59  1.304927      0.576742       large  \n",
       "60  1.400866      0.647690       large  \n",
       "61  1.191905      0.533265       large  \n",
       "62  0.895953      0.416679      medium  \n",
       "63  0.867633      0.387422      medium  \n",
       "\n",
       "[64 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df = get_corr_stats(df_analysis, binary=False, feats=[f\"surprisal_buggy_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_{mid}\" for mid in models_ids] + [f\"surprisal_buggy_cloze_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_cloze_{mid}\" for mid in models_ids], score_col=\"score\", binary_col='labels')\n",
    "corr_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18bc471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>pearson_coef</th>\n",
       "      <th>pearson_p</th>\n",
       "      <th>spearman_coef</th>\n",
       "      <th>spearman_p</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>surprisal_fixed_gpt2</td>\n",
       "      <td>0.419356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638173</td>\n",
       "      <td>0.819087</td>\n",
       "      <td>1.324369e-93</td>\n",
       "      <td>1.387056</td>\n",
       "      <td>0.638173</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>surprisal_fixed_gpt2-xl</td>\n",
       "      <td>0.372670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566399</td>\n",
       "      <td>0.783199</td>\n",
       "      <td>3.897887e-74</td>\n",
       "      <td>1.198972</td>\n",
       "      <td>0.566399</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>surprisal_fixed_gpt2-medium</td>\n",
       "      <td>0.388760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599864</td>\n",
       "      <td>0.799932</td>\n",
       "      <td>6.316364e-83</td>\n",
       "      <td>1.281146</td>\n",
       "      <td>0.599864</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>surprisal_fixed_gpt2-large</td>\n",
       "      <td>0.381318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585406</td>\n",
       "      <td>0.792703</td>\n",
       "      <td>4.566711e-79</td>\n",
       "      <td>1.222675</td>\n",
       "      <td>0.585406</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2</td>\n",
       "      <td>0.489977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686721</td>\n",
       "      <td>0.843360</td>\n",
       "      <td>4.412006e-108</td>\n",
       "      <td>1.564582</td>\n",
       "      <td>0.686721</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-xl</td>\n",
       "      <td>0.446167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.629093</td>\n",
       "      <td>0.814546</td>\n",
       "      <td>5.159335e-91</td>\n",
       "      <td>1.334066</td>\n",
       "      <td>0.629093</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-medium</td>\n",
       "      <td>0.466418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668073</td>\n",
       "      <td>0.834037</td>\n",
       "      <td>2.140553e-102</td>\n",
       "      <td>1.431831</td>\n",
       "      <td>0.668073</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.455469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647690</td>\n",
       "      <td>0.823845</td>\n",
       "      <td>2.329887e-96</td>\n",
       "      <td>1.400866</td>\n",
       "      <td>0.647690</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  pearson_coef  pearson_p  spearman_coef  \\\n",
       "17               surprisal_fixed_gpt2      0.419356        0.0       0.416970   \n",
       "20            surprisal_fixed_gpt2-xl      0.372670        0.0       0.361610   \n",
       "24        surprisal_fixed_gpt2-medium      0.388760        0.0       0.382743   \n",
       "28         surprisal_fixed_gpt2-large      0.381318        0.0       0.372997   \n",
       "49         surprisal_fixed_cloze_gpt2      0.489977        0.0       0.499379   \n",
       "52      surprisal_fixed_cloze_gpt2-xl      0.446167        0.0       0.451687   \n",
       "56  surprisal_fixed_cloze_gpt2-medium      0.466418        0.0       0.473070   \n",
       "60   surprisal_fixed_cloze_gpt2-large      0.455469        0.0       0.459231   \n",
       "\n",
       "    spearman_p  rank_biserial_r       auc           mw_p  cohens_d  \\\n",
       "17         0.0         0.638173  0.819087   1.324369e-93  1.387056   \n",
       "20         0.0         0.566399  0.783199   3.897887e-74  1.198972   \n",
       "24         0.0         0.599864  0.799932   6.316364e-83  1.281146   \n",
       "28         0.0         0.585406  0.792703   4.566711e-79  1.222675   \n",
       "49         0.0         0.686721  0.843360  4.412006e-108  1.564582   \n",
       "52         0.0         0.629093  0.814546   5.159335e-91  1.334066   \n",
       "56         0.0         0.668073  0.834037  2.140553e-102  1.431831   \n",
       "60         0.0         0.647690  0.823845   2.329887e-96  1.400866   \n",
       "\n",
       "    cliffs_delta cliffs_size  \n",
       "17      0.638173       large  \n",
       "20      0.566399       large  \n",
       "24      0.599864       large  \n",
       "28      0.585406       large  \n",
       "49      0.686721       large  \n",
       "52      0.629093       large  \n",
       "56      0.668073       large  \n",
       "60      0.647690       large  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df[(corr_res_df['feature'].str.contains(\"surprisal_fixed\")) & (corr_res_df['feature'].str.contains(\"gpt\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04493090",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ids_ordered = [\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "        \n",
    "    'Llama-3.2-1B',\n",
    "    'Llama-3.2-1B-Instruct',\n",
    "    'Llama-3.2-3B',\n",
    "    'Llama-3.2-3B-Instruct',\n",
    "    'Llama-3.1-8B',\n",
    "    'Llama-3.1-8B-Instruct',    \n",
    "\n",
    "    'Qwen2.5-0.5B',    \n",
    "    'Qwen2.5-0.5B-Instruct',\n",
    "    'Qwen2.5-7B',\n",
    "    'Qwen2.5-7B-Instruct',    \n",
    "    'Qwen2.5-14B',    \n",
    "    'Qwen2.5-14B-Instruct',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d03d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "sp = []\n",
    "rb = []\n",
    "auc = []\n",
    "mw_p = []\n",
    "c_delta = []\n",
    "cloze_gain = []\n",
    "instruct_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    ps.append(corr_res_df[corr_res_df['feature']==feat].pearson_coef.item())\n",
    "    sp.append(corr_res_df[corr_res_df['feature']==feat].spearman_coef.item())\n",
    "    rb.append(corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    auc.append(corr_res_df[corr_res_df['feature']==feat].auc.item())\n",
    "    mw_p.append(corr_res_df[corr_res_df['feature']==feat].mw_p.item())\n",
    "    c_delta.append(corr_res_df[corr_res_df['feature']==feat].cliffs_delta.item())\n",
    "    feat_cloze = f\"surprisal_fixed_cloze_{m}\"\n",
    "    cloze_gain.append(corr_res_df[corr_res_df['feature']==feat_cloze].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803fa1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>pearson_coef</th>\n",
       "      <th>spearman_coef</th>\n",
       "      <th>rank_biserial</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cloze_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.419356</td>\n",
       "      <td>0.416970</td>\n",
       "      <td>0.638173</td>\n",
       "      <td>0.819087</td>\n",
       "      <td>1.324369e-93</td>\n",
       "      <td>0.638173</td>\n",
       "      <td>0.048548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.388760</td>\n",
       "      <td>0.382743</td>\n",
       "      <td>0.599864</td>\n",
       "      <td>0.799932</td>\n",
       "      <td>6.316364e-83</td>\n",
       "      <td>0.599864</td>\n",
       "      <td>0.068209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>0.381318</td>\n",
       "      <td>0.372997</td>\n",
       "      <td>0.585406</td>\n",
       "      <td>0.792703</td>\n",
       "      <td>4.566711e-79</td>\n",
       "      <td>0.585406</td>\n",
       "      <td>0.062283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0.372670</td>\n",
       "      <td>0.361610</td>\n",
       "      <td>0.566399</td>\n",
       "      <td>0.783199</td>\n",
       "      <td>3.897887e-74</td>\n",
       "      <td>0.566399</td>\n",
       "      <td>0.062694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.345477</td>\n",
       "      <td>0.329036</td>\n",
       "      <td>0.531529</td>\n",
       "      <td>0.765764</td>\n",
       "      <td>1.646120e-65</td>\n",
       "      <td>0.531529</td>\n",
       "      <td>0.072926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.352542</td>\n",
       "      <td>0.336520</td>\n",
       "      <td>0.571543</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>1.871054e-75</td>\n",
       "      <td>0.571543</td>\n",
       "      <td>-0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.327924</td>\n",
       "      <td>0.307517</td>\n",
       "      <td>0.501866</td>\n",
       "      <td>0.750933</td>\n",
       "      <td>1.335718e-58</td>\n",
       "      <td>0.501866</td>\n",
       "      <td>-0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.334822</td>\n",
       "      <td>0.318221</td>\n",
       "      <td>0.541710</td>\n",
       "      <td>0.770855</td>\n",
       "      <td>5.679679e-68</td>\n",
       "      <td>0.541710</td>\n",
       "      <td>-0.110761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.314009</td>\n",
       "      <td>0.292605</td>\n",
       "      <td>0.488208</td>\n",
       "      <td>0.744104</td>\n",
       "      <td>1.494840e-55</td>\n",
       "      <td>0.488208</td>\n",
       "      <td>0.019069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.313899</td>\n",
       "      <td>0.294948</td>\n",
       "      <td>0.503829</td>\n",
       "      <td>0.751915</td>\n",
       "      <td>4.792042e-59</td>\n",
       "      <td>0.503829</td>\n",
       "      <td>-0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>0.383839</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>0.597532</td>\n",
       "      <td>0.798766</td>\n",
       "      <td>2.687684e-82</td>\n",
       "      <td>0.597532</td>\n",
       "      <td>-0.020790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>0.362153</td>\n",
       "      <td>0.369186</td>\n",
       "      <td>0.581433</td>\n",
       "      <td>0.790717</td>\n",
       "      <td>5.055141e-78</td>\n",
       "      <td>0.581433</td>\n",
       "      <td>-0.045347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>0.333820</td>\n",
       "      <td>0.314120</td>\n",
       "      <td>0.502303</td>\n",
       "      <td>0.751151</td>\n",
       "      <td>1.063445e-58</td>\n",
       "      <td>0.502303</td>\n",
       "      <td>0.037049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.315031</td>\n",
       "      <td>0.297024</td>\n",
       "      <td>0.485776</td>\n",
       "      <td>0.742888</td>\n",
       "      <td>5.113450e-55</td>\n",
       "      <td>0.485776</td>\n",
       "      <td>-0.069097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>0.316053</td>\n",
       "      <td>0.295481</td>\n",
       "      <td>0.470378</td>\n",
       "      <td>0.735189</td>\n",
       "      <td>1.069223e-51</td>\n",
       "      <td>0.470378</td>\n",
       "      <td>0.058399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.270909</td>\n",
       "      <td>0.254708</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>0.715614</td>\n",
       "      <td>9.856924e-44</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>-0.043807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  pearson_coef  spearman_coef  rank_biserial  \\\n",
       "0                    gpt2      0.419356       0.416970       0.638173   \n",
       "1             gpt2-medium      0.388760       0.382743       0.599864   \n",
       "2              gpt2-large      0.381318       0.372997       0.585406   \n",
       "3                 gpt2-xl      0.372670       0.361610       0.566399   \n",
       "4            Llama-3.2-1B      0.345477       0.329036       0.531529   \n",
       "5   Llama-3.2-1B-Instruct      0.352542       0.336520       0.571543   \n",
       "6            Llama-3.2-3B      0.327924       0.307517       0.501866   \n",
       "7   Llama-3.2-3B-Instruct      0.334822       0.318221       0.541710   \n",
       "8            Llama-3.1-8B      0.314009       0.292605       0.488208   \n",
       "9   Llama-3.1-8B-Instruct      0.313899       0.294948       0.503829   \n",
       "10           Qwen2.5-0.5B      0.383839       0.377340       0.597532   \n",
       "11  Qwen2.5-0.5B-Instruct      0.362153       0.369186       0.581433   \n",
       "12             Qwen2.5-7B      0.333820       0.314120       0.502303   \n",
       "13    Qwen2.5-7B-Instruct      0.315031       0.297024       0.485776   \n",
       "14            Qwen2.5-14B      0.316053       0.295481       0.470378   \n",
       "15   Qwen2.5-14B-Instruct      0.270909       0.254708       0.431229   \n",
       "\n",
       "         auc          mw_p  cliffs_delta  cloze_gain  \n",
       "0   0.819087  1.324369e-93      0.638173    0.048548  \n",
       "1   0.799932  6.316364e-83      0.599864    0.068209  \n",
       "2   0.792703  4.566711e-79      0.585406    0.062283  \n",
       "3   0.783199  3.897887e-74      0.566399    0.062694  \n",
       "4   0.765764  1.646120e-65      0.531529    0.072926  \n",
       "5   0.785772  1.871054e-75      0.571543   -0.038278  \n",
       "6   0.750933  1.335718e-58      0.501866   -0.005119  \n",
       "7   0.770855  5.679679e-68      0.541710   -0.110761  \n",
       "8   0.744104  1.494840e-55      0.488208    0.019069  \n",
       "9   0.751915  4.792042e-59      0.503829   -0.077552  \n",
       "10  0.798766  2.687684e-82      0.597532   -0.020790  \n",
       "11  0.790717  5.055141e-78      0.581433   -0.045347  \n",
       "12  0.751151  1.063445e-58      0.502303    0.037049  \n",
       "13  0.742888  5.113450e-55      0.485776   -0.069097  \n",
       "14  0.735189  1.069223e-51      0.470378    0.058399  \n",
       "15  0.715614  9.856924e-44      0.431229   -0.043807  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vua_dinh_t_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"pearson_coef\": ps,\n",
    "    \"spearman_coef\": sp,\n",
    "    \"rank_biserial\": rb,\n",
    "    \"auc\": auc,\n",
    "    \"mw_p\": mw_p,\n",
    "    \"cliffs_delta\": c_delta,\n",
    "    \"cloze_gain\": cloze_gain\n",
    "})\n",
    "vua_dinh_t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0501fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    feat_instruct = f\"{feat}-Instruct\"\n",
    "    if feat_instruct in corr_res_df['feature'].values:\n",
    "        instruct_gain.append(corr_res_df[corr_res_df['feature']==feat_instruct].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    else:\n",
    "        instruct_gain.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e4800c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>instruct_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.040014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.039844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.015622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>-0.016098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>-0.016527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>-0.039149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  instruct_gain\n",
       "0                    gpt2            NaN\n",
       "1             gpt2-medium            NaN\n",
       "2              gpt2-large            NaN\n",
       "3                 gpt2-xl            NaN\n",
       "4            Llama-3.2-1B       0.040014\n",
       "5   Llama-3.2-1B-Instruct            NaN\n",
       "6            Llama-3.2-3B       0.039844\n",
       "7   Llama-3.2-3B-Instruct            NaN\n",
       "8            Llama-3.1-8B       0.015622\n",
       "9   Llama-3.1-8B-Instruct            NaN\n",
       "10           Qwen2.5-0.5B      -0.016098\n",
       "11  Qwen2.5-0.5B-Instruct            NaN\n",
       "12             Qwen2.5-7B      -0.016527\n",
       "13    Qwen2.5-7B-Instruct            NaN\n",
       "14            Qwen2.5-14B      -0.039149\n",
       "15   Qwen2.5-14B-Instruct            NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vua_dinh_t2_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"instruct_gain\": instruct_gain\n",
    "})\n",
    "vua_dinh_t2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19951c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce8737dd",
   "metadata": {},
   "source": [
    "# VUA-dictionary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a309f0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Llama-3.2-3B',\n",
       "  'gpt2',\n",
       "  'Llama-3.1-8B-Instruct',\n",
       "  'Qwen2.5-7B',\n",
       "  'gpt2-xl',\n",
       "  'Llama-3.2-3B-Instruct',\n",
       "  'Llama-3.1-8B',\n",
       "  'Qwen2.5-14B',\n",
       "  'gpt2-medium',\n",
       "  'Llama-3.2-1B',\n",
       "  'Qwen2.5-0.5B-Instruct',\n",
       "  'Qwen2.5-0.5B',\n",
       "  'gpt2-large',\n",
       "  'Llama-3.2-1B-Instruct',\n",
       "  'Qwen2.5-7B-Instruct',\n",
       "  'Qwen2.5-14B-Instruct'],\n",
       " 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ids, len(models_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8e7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16202 entries, 0 to 16201\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   document_id             16202 non-null  object\n",
      " 1   sentence_id             16202 non-null  object\n",
      " 2   sentence                16202 non-null  object\n",
      " 3   words_list              16202 non-null  object\n",
      " 4   offsets                 16202 non-null  object\n",
      " 5   vua_metaphor_labels     16202 non-null  object\n",
      " 6   do_dinh_scores          16202 non-null  object\n",
      " 7   reimann_novelty_labels  16202 non-null  object\n",
      " 8   genre                   16202 non-null  object\n",
      " 9   subtoken_ids            16202 non-null  object\n",
      " 10  subtoken_strs           16202 non-null  object\n",
      " 11  surprisal_buggy         16202 non-null  object\n",
      " 12  surprisal_fixed         16202 non-null  object\n",
      " 13  subtoken_ids_cloze      16202 non-null  object\n",
      " 14  subtoken_strs_cloze     16202 non-null  object\n",
      " 15  surprisal_buggy_cloze   16202 non-null  object\n",
      " 16  surprisal_fixed_cloze   16202 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "all_results[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c3bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame()\n",
    "for k, df in enumerate(all_results):\n",
    "    reimann_labels = []\n",
    "    surp_buggy = []\n",
    "    surp_fixed = []\n",
    "    surp_buggy_cloze = []\n",
    "    surp_fixed_cloze = []\n",
    "    gens = []\n",
    "    for i, row in df.iterrows():\n",
    "        for j, label in enumerate(row['vua_metaphor_labels']):\n",
    "            if label == True:\n",
    "                scs = row['do_dinh_scores'][j]\n",
    "                scs = max([float(s) for s in scs.split(\",\")])\n",
    "                if scs > -1:\n",
    "                    if row['reimann_novelty_labels'][j] == True:\n",
    "                        reimann_labels.append(\"novel\")\n",
    "                    else:\n",
    "                        reimann_labels.append(\"conventional\")\n",
    "                    surp_buggy.append(row['surprisal_buggy'][j].item())\n",
    "                    surp_fixed.append(row['surprisal_fixed'][j].item())\n",
    "                    surp_buggy_cloze.append(row['surprisal_buggy_cloze'][j].item())\n",
    "                    surp_fixed_cloze.append(row['surprisal_fixed_cloze'][j].item())\n",
    "                    gens.append(row['genre'])\n",
    "\n",
    "    df_analysis['reimann_labels'] = reimann_labels\n",
    "    df_analysis[f\"surprisal_buggy_{models_ids[k]}\"] = surp_buggy\n",
    "    df_analysis[f\"surprisal_fixed_{models_ids[k]}\"] = surp_fixed\n",
    "    df_analysis[f\"surprisal_buggy_cloze_{models_ids[k]}\"] = surp_buggy_cloze\n",
    "    df_analysis[f\"surprisal_fixed_cloze_{models_ids[k]}\"] = surp_fixed_cloze\n",
    "    df_analysis[f\"genre\"] = gens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dc7ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15155 entries, 0 to 15154\n",
      "Data columns (total 66 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   reimann_labels                               15155 non-null  object \n",
      " 1   surprisal_buggy_Llama-3.2-3B                 15155 non-null  float64\n",
      " 2   surprisal_fixed_Llama-3.2-3B                 15155 non-null  float64\n",
      " 3   surprisal_buggy_cloze_Llama-3.2-3B           15155 non-null  float64\n",
      " 4   surprisal_fixed_cloze_Llama-3.2-3B           15155 non-null  float64\n",
      " 5   genre                                        15155 non-null  object \n",
      " 6   surprisal_buggy_gpt2                         15155 non-null  float64\n",
      " 7   surprisal_fixed_gpt2                         15155 non-null  float64\n",
      " 8   surprisal_buggy_cloze_gpt2                   15155 non-null  float64\n",
      " 9   surprisal_fixed_cloze_gpt2                   15155 non-null  float64\n",
      " 10  surprisal_buggy_Llama-3.1-8B-Instruct        15155 non-null  float64\n",
      " 11  surprisal_fixed_Llama-3.1-8B-Instruct        15155 non-null  float64\n",
      " 12  surprisal_buggy_cloze_Llama-3.1-8B-Instruct  15155 non-null  float64\n",
      " 13  surprisal_fixed_cloze_Llama-3.1-8B-Instruct  15155 non-null  float64\n",
      " 14  surprisal_buggy_Qwen2.5-7B                   15155 non-null  float64\n",
      " 15  surprisal_fixed_Qwen2.5-7B                   15155 non-null  float64\n",
      " 16  surprisal_buggy_cloze_Qwen2.5-7B             15155 non-null  float64\n",
      " 17  surprisal_fixed_cloze_Qwen2.5-7B             15155 non-null  float64\n",
      " 18  surprisal_buggy_gpt2-xl                      15155 non-null  float64\n",
      " 19  surprisal_fixed_gpt2-xl                      15155 non-null  float64\n",
      " 20  surprisal_buggy_cloze_gpt2-xl                15155 non-null  float64\n",
      " 21  surprisal_fixed_cloze_gpt2-xl                15155 non-null  float64\n",
      " 22  surprisal_buggy_Llama-3.2-3B-Instruct        15155 non-null  float64\n",
      " 23  surprisal_fixed_Llama-3.2-3B-Instruct        15155 non-null  float64\n",
      " 24  surprisal_buggy_cloze_Llama-3.2-3B-Instruct  15155 non-null  float64\n",
      " 25  surprisal_fixed_cloze_Llama-3.2-3B-Instruct  15155 non-null  float64\n",
      " 26  surprisal_buggy_Llama-3.1-8B                 15155 non-null  float64\n",
      " 27  surprisal_fixed_Llama-3.1-8B                 15155 non-null  float64\n",
      " 28  surprisal_buggy_cloze_Llama-3.1-8B           15155 non-null  float64\n",
      " 29  surprisal_fixed_cloze_Llama-3.1-8B           15155 non-null  float64\n",
      " 30  surprisal_buggy_Qwen2.5-14B                  15155 non-null  float64\n",
      " 31  surprisal_fixed_Qwen2.5-14B                  15155 non-null  float64\n",
      " 32  surprisal_buggy_cloze_Qwen2.5-14B            15155 non-null  float64\n",
      " 33  surprisal_fixed_cloze_Qwen2.5-14B            15155 non-null  float64\n",
      " 34  surprisal_buggy_gpt2-medium                  15155 non-null  float64\n",
      " 35  surprisal_fixed_gpt2-medium                  15155 non-null  float64\n",
      " 36  surprisal_buggy_cloze_gpt2-medium            15155 non-null  float64\n",
      " 37  surprisal_fixed_cloze_gpt2-medium            15155 non-null  float64\n",
      " 38  surprisal_buggy_Llama-3.2-1B                 15155 non-null  float64\n",
      " 39  surprisal_fixed_Llama-3.2-1B                 15155 non-null  float64\n",
      " 40  surprisal_buggy_cloze_Llama-3.2-1B           15155 non-null  float64\n",
      " 41  surprisal_fixed_cloze_Llama-3.2-1B           15155 non-null  float64\n",
      " 42  surprisal_buggy_Qwen2.5-0.5B-Instruct        15155 non-null  float64\n",
      " 43  surprisal_fixed_Qwen2.5-0.5B-Instruct        15155 non-null  float64\n",
      " 44  surprisal_buggy_cloze_Qwen2.5-0.5B-Instruct  15155 non-null  float64\n",
      " 45  surprisal_fixed_cloze_Qwen2.5-0.5B-Instruct  15155 non-null  float64\n",
      " 46  surprisal_buggy_Qwen2.5-0.5B                 15155 non-null  float64\n",
      " 47  surprisal_fixed_Qwen2.5-0.5B                 15155 non-null  float64\n",
      " 48  surprisal_buggy_cloze_Qwen2.5-0.5B           15155 non-null  float64\n",
      " 49  surprisal_fixed_cloze_Qwen2.5-0.5B           15155 non-null  float64\n",
      " 50  surprisal_buggy_gpt2-large                   15155 non-null  float64\n",
      " 51  surprisal_fixed_gpt2-large                   15155 non-null  float64\n",
      " 52  surprisal_buggy_cloze_gpt2-large             15155 non-null  float64\n",
      " 53  surprisal_fixed_cloze_gpt2-large             15155 non-null  float64\n",
      " 54  surprisal_buggy_Llama-3.2-1B-Instruct        15155 non-null  float64\n",
      " 55  surprisal_fixed_Llama-3.2-1B-Instruct        15155 non-null  float64\n",
      " 56  surprisal_buggy_cloze_Llama-3.2-1B-Instruct  15155 non-null  float64\n",
      " 57  surprisal_fixed_cloze_Llama-3.2-1B-Instruct  15155 non-null  float64\n",
      " 58  surprisal_buggy_Qwen2.5-7B-Instruct          15155 non-null  float64\n",
      " 59  surprisal_fixed_Qwen2.5-7B-Instruct          15155 non-null  float64\n",
      " 60  surprisal_buggy_cloze_Qwen2.5-7B-Instruct    15155 non-null  float64\n",
      " 61  surprisal_fixed_cloze_Qwen2.5-7B-Instruct    15155 non-null  float64\n",
      " 62  surprisal_buggy_Qwen2.5-14B-Instruct         15155 non-null  float64\n",
      " 63  surprisal_fixed_Qwen2.5-14B-Instruct         15155 non-null  float64\n",
      " 64  surprisal_buggy_cloze_Qwen2.5-14B-Instruct   15155 non-null  float64\n",
      " 65  surprisal_fixed_cloze_Qwen2.5-14B-Instruct   15155 non-null  float64\n",
      "dtypes: float64(64), object(2)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6379b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprisal_buggy_Llama-3.2-3B</td>\n",
       "      <td>0.447458</td>\n",
       "      <td>0.723729</td>\n",
       "      <td>6.424206e-54</td>\n",
       "      <td>0.975800</td>\n",
       "      <td>0.447458</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprisal_buggy_gpt2</td>\n",
       "      <td>0.579478</td>\n",
       "      <td>0.789739</td>\n",
       "      <td>3.552858e-89</td>\n",
       "      <td>1.246111</td>\n",
       "      <td>0.579478</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprisal_buggy_Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.437940</td>\n",
       "      <td>0.718970</td>\n",
       "      <td>1.004047e-51</td>\n",
       "      <td>0.929559</td>\n",
       "      <td>0.437940</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisal_buggy_Qwen2.5-7B</td>\n",
       "      <td>0.461694</td>\n",
       "      <td>0.730847</td>\n",
       "      <td>2.749185e-57</td>\n",
       "      <td>1.024853</td>\n",
       "      <td>0.461694</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprisal_buggy_gpt2-xl</td>\n",
       "      <td>0.525908</td>\n",
       "      <td>0.762954</td>\n",
       "      <td>8.771888e-74</td>\n",
       "      <td>1.131283</td>\n",
       "      <td>0.525908</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-0.5B</td>\n",
       "      <td>0.563635</td>\n",
       "      <td>0.781817</td>\n",
       "      <td>1.809192e-84</td>\n",
       "      <td>1.256417</td>\n",
       "      <td>0.563635</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.621402</td>\n",
       "      <td>0.810701</td>\n",
       "      <td>2.946428e-102</td>\n",
       "      <td>1.365454</td>\n",
       "      <td>0.621402</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>surprisal_fixed_cloze_Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.483266</td>\n",
       "      <td>0.741633</td>\n",
       "      <td>1.365239e-62</td>\n",
       "      <td>1.064454</td>\n",
       "      <td>0.483266</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.420359</td>\n",
       "      <td>0.710180</td>\n",
       "      <td>8.532921e-48</td>\n",
       "      <td>0.905683</td>\n",
       "      <td>0.420359</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.702812</td>\n",
       "      <td>1.263907e-44</td>\n",
       "      <td>0.971239</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feature  rank_biserial_r       auc  \\\n",
       "0                  surprisal_buggy_Llama-3.2-3B         0.447458  0.723729   \n",
       "1                          surprisal_buggy_gpt2         0.579478  0.789739   \n",
       "2         surprisal_buggy_Llama-3.1-8B-Instruct         0.437940  0.718970   \n",
       "3                    surprisal_buggy_Qwen2.5-7B         0.461694  0.730847   \n",
       "4                       surprisal_buggy_gpt2-xl         0.525908  0.762954   \n",
       "..                                          ...              ...       ...   \n",
       "59           surprisal_fixed_cloze_Qwen2.5-0.5B         0.563635  0.781817   \n",
       "60             surprisal_fixed_cloze_gpt2-large         0.621402  0.810701   \n",
       "61  surprisal_fixed_cloze_Llama-3.2-1B-Instruct         0.483266  0.741633   \n",
       "62    surprisal_fixed_cloze_Qwen2.5-7B-Instruct         0.420359  0.710180   \n",
       "63   surprisal_fixed_cloze_Qwen2.5-14B-Instruct         0.405623  0.702812   \n",
       "\n",
       "             mw_p  cohens_d  cliffs_delta cliffs_size  \n",
       "0    6.424206e-54  0.975800      0.447458      medium  \n",
       "1    3.552858e-89  1.246111      0.579478       large  \n",
       "2    1.004047e-51  0.929559      0.437940      medium  \n",
       "3    2.749185e-57  1.024853      0.461694      medium  \n",
       "4    8.771888e-74  1.131283      0.525908       large  \n",
       "..            ...       ...           ...         ...  \n",
       "59   1.809192e-84  1.256417      0.563635       large  \n",
       "60  2.946428e-102  1.365454      0.621402       large  \n",
       "61   1.365239e-62  1.064454      0.483266       large  \n",
       "62   8.532921e-48  0.905683      0.420359      medium  \n",
       "63   1.263907e-44  0.971239      0.405623      medium  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df = get_corr_stats(df_analysis, binary=True, feats=[f\"surprisal_buggy_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_{mid}\" for mid in models_ids] + [f\"surprisal_buggy_cloze_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_cloze_{mid}\" for mid in models_ids], score_col=\"score\", binary_col='reimann_labels')\n",
    "corr_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8733e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = []\n",
    "auc = []\n",
    "mw_p = []\n",
    "c_delta = []\n",
    "cloze_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    rb.append(corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    auc.append(corr_res_df[corr_res_df['feature']==feat].auc.item())\n",
    "    mw_p.append(corr_res_df[corr_res_df['feature']==feat].mw_p.item())\n",
    "    c_delta.append(corr_res_df[corr_res_df['feature']==feat].cliffs_delta.item())\n",
    "    feat_cloze = f\"surprisal_fixed_cloze_{m}\"\n",
    "    cloze_gain.append(corr_res_df[corr_res_df['feature']==feat_cloze].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd3d3b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rank_biserial</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cloze_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.581174</td>\n",
       "      <td>0.790587</td>\n",
       "      <td>1.094118e-89</td>\n",
       "      <td>0.581174</td>\n",
       "      <td>0.039752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.556553</td>\n",
       "      <td>0.778276</td>\n",
       "      <td>2.086702e-82</td>\n",
       "      <td>0.556553</td>\n",
       "      <td>0.045184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>0.538914</td>\n",
       "      <td>0.769457</td>\n",
       "      <td>2.199687e-77</td>\n",
       "      <td>0.538914</td>\n",
       "      <td>0.082488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0.527637</td>\n",
       "      <td>0.763819</td>\n",
       "      <td>2.947510e-74</td>\n",
       "      <td>0.527637</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.479858</td>\n",
       "      <td>0.739929</td>\n",
       "      <td>9.754953e-62</td>\n",
       "      <td>0.479858</td>\n",
       "      <td>0.079907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>1.410470e-65</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>-0.011733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.445622</td>\n",
       "      <td>0.722811</td>\n",
       "      <td>1.716969e-53</td>\n",
       "      <td>0.445622</td>\n",
       "      <td>0.055624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.469793</td>\n",
       "      <td>0.734897</td>\n",
       "      <td>2.992496e-59</td>\n",
       "      <td>0.469793</td>\n",
       "      <td>-0.023346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.431481</td>\n",
       "      <td>0.715741</td>\n",
       "      <td>2.909244e-50</td>\n",
       "      <td>0.431481</td>\n",
       "      <td>0.026892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.437062</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>1.591749e-51</td>\n",
       "      <td>0.437062</td>\n",
       "      <td>-0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>0.542846</td>\n",
       "      <td>0.771423</td>\n",
       "      <td>1.724617e-78</td>\n",
       "      <td>0.542846</td>\n",
       "      <td>0.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.767550</td>\n",
       "      <td>2.554928e-76</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>-0.015876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>0.456145</td>\n",
       "      <td>0.728072</td>\n",
       "      <td>5.818852e-56</td>\n",
       "      <td>0.456145</td>\n",
       "      <td>0.055955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.436671</td>\n",
       "      <td>0.718336</td>\n",
       "      <td>1.952828e-51</td>\n",
       "      <td>0.436671</td>\n",
       "      <td>-0.016312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>0.429763</td>\n",
       "      <td>0.714882</td>\n",
       "      <td>7.064511e-50</td>\n",
       "      <td>0.429763</td>\n",
       "      <td>0.077837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.398299</td>\n",
       "      <td>0.699149</td>\n",
       "      <td>4.324740e-43</td>\n",
       "      <td>0.398299</td>\n",
       "      <td>0.007324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  rank_biserial       auc          mw_p  \\\n",
       "0                    gpt2       0.581174  0.790587  1.094118e-89   \n",
       "1             gpt2-medium       0.556553  0.778276  2.086702e-82   \n",
       "2              gpt2-large       0.538914  0.769457  2.199687e-77   \n",
       "3                 gpt2-xl       0.527637  0.763819  2.947510e-74   \n",
       "4            Llama-3.2-1B       0.479858  0.739929  9.754953e-62   \n",
       "5   Llama-3.2-1B-Instruct       0.494999  0.747500  1.410470e-65   \n",
       "6            Llama-3.2-3B       0.445622  0.722811  1.716969e-53   \n",
       "7   Llama-3.2-3B-Instruct       0.469793  0.734897  2.992496e-59   \n",
       "8            Llama-3.1-8B       0.431481  0.715741  2.909244e-50   \n",
       "9   Llama-3.1-8B-Instruct       0.437062  0.718531  1.591749e-51   \n",
       "10           Qwen2.5-0.5B       0.542846  0.771423  1.724617e-78   \n",
       "11  Qwen2.5-0.5B-Instruct       0.535100  0.767550  2.554928e-76   \n",
       "12             Qwen2.5-7B       0.456145  0.728072  5.818852e-56   \n",
       "13    Qwen2.5-7B-Instruct       0.436671  0.718336  1.952828e-51   \n",
       "14            Qwen2.5-14B       0.429763  0.714882  7.064511e-50   \n",
       "15   Qwen2.5-14B-Instruct       0.398299  0.699149  4.324740e-43   \n",
       "\n",
       "    cliffs_delta  cloze_gain  \n",
       "0       0.581174    0.039752  \n",
       "1       0.556553    0.045184  \n",
       "2       0.538914    0.082488  \n",
       "3       0.527637    0.025300  \n",
       "4       0.479858    0.079907  \n",
       "5       0.494999   -0.011733  \n",
       "6       0.445622    0.055624  \n",
       "7       0.469793   -0.023346  \n",
       "8       0.431481    0.026892  \n",
       "9       0.437062   -0.001929  \n",
       "10      0.542846    0.020789  \n",
       "11      0.535100   -0.015876  \n",
       "12      0.456145    0.055955  \n",
       "13      0.436671   -0.016312  \n",
       "14      0.429763    0.077837  \n",
       "15      0.398299    0.007324  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vua_reimann_t_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"rank_biserial\": rb,\n",
    "    \"auc\": auc,\n",
    "    \"mw_p\": mw_p,\n",
    "    \"cliffs_delta\": c_delta,\n",
    "    \"cloze_gain\": cloze_gain\n",
    "})\n",
    "vua_reimann_t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2843c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    feat_instruct = f\"{feat}-Instruct\"\n",
    "    if feat_instruct in corr_res_df['feature'].values:\n",
    "        instruct_gain.append(corr_res_df[corr_res_df['feature']==feat_instruct].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    else:\n",
    "        instruct_gain.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3f3a729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>instruct_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.015141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.024171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.005580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>-0.007746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>-0.019473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>-0.031465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  instruct_gain\n",
       "0                    gpt2            NaN\n",
       "1             gpt2-medium            NaN\n",
       "2              gpt2-large            NaN\n",
       "3                 gpt2-xl            NaN\n",
       "4            Llama-3.2-1B       0.015141\n",
       "5   Llama-3.2-1B-Instruct            NaN\n",
       "6            Llama-3.2-3B       0.024171\n",
       "7   Llama-3.2-3B-Instruct            NaN\n",
       "8            Llama-3.1-8B       0.005580\n",
       "9   Llama-3.1-8B-Instruct            NaN\n",
       "10           Qwen2.5-0.5B      -0.007746\n",
       "11  Qwen2.5-0.5B-Instruct            NaN\n",
       "12             Qwen2.5-7B      -0.019473\n",
       "13    Qwen2.5-7B-Instruct            NaN\n",
       "14            Qwen2.5-14B      -0.031465\n",
       "15   Qwen2.5-14B-Instruct            NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vua_reimann_t2_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"instruct_gain\": instruct_gain\n",
    "})\n",
    "vua_reimann_t2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bee2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accc1616",
   "metadata": {},
   "source": [
    "# LAI2009 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daee688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LAI2009-METANOV_mod_openai-community_gpt2_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_meta-llama_Llama-3.2-1B_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_meta-llama_Llama-3.1-8B_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_meta-llama_Llama-3.2-1B-Instruct_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_Qwen_Qwen2.5-14B-Instruct_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_Qwen_Qwen2.5-7B-Instruct_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_openai-community_gpt2-xl_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_openai-community_gpt2-medium_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_meta-llama_Llama-3.2-3B-Instruct_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_Qwen_Qwen2.5-7B_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_meta-llama_Llama-3.2-3B_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_meta-llama_Llama-3.1-8B-Instruct_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_Qwen_Qwen2.5-0.5B_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_Qwen_Qwen2.5-0.5B-Instruct_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_openai-community_gpt2-large_cloze_pimentel.parquet...\n",
      "Loading LAI2009-METANOV_mod_Qwen_Qwen2.5-14B_cloze_pimentel.parquet...\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "models_ids = []\n",
    "for f in os.listdir(\"results\"):\n",
    "    if f.endswith(\".parquet\") and \"LAI\" in f:\n",
    "        print(f\"Loading {f}...\")\n",
    "        df_part = pd.read_parquet(os.path.join(\"results\", f))\n",
    "        all_results.append(df_part)\n",
    "        models_ids.append(f.split(\"_\")[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c42430cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gpt2',\n",
       "  'Llama-3.2-1B',\n",
       "  'Llama-3.1-8B',\n",
       "  'Llama-3.2-1B-Instruct',\n",
       "  'Qwen2.5-14B-Instruct',\n",
       "  'Qwen2.5-7B-Instruct',\n",
       "  'gpt2-xl',\n",
       "  'gpt2-medium',\n",
       "  'Llama-3.2-3B-Instruct',\n",
       "  'Qwen2.5-7B',\n",
       "  'Llama-3.2-3B',\n",
       "  'Llama-3.1-8B-Instruct',\n",
       "  'Qwen2.5-0.5B',\n",
       "  'Qwen2.5-0.5B-Instruct',\n",
       "  'gpt2-large',\n",
       "  'Qwen2.5-14B'],\n",
       " 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ids, len(models_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "390295a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   sentence               208 non-null    object \n",
      " 1   target_word            208 non-null    object \n",
      " 2   novelty_label          208 non-null    object \n",
      " 3   offsets                208 non-null    object \n",
      " 4   subtoken_ids           208 non-null    object \n",
      " 5   subtoken_strs          208 non-null    object \n",
      " 6   surprisal_buggy        208 non-null    float64\n",
      " 7   surprisal_fixed        208 non-null    float64\n",
      " 8   subtoken_ids_cloze     208 non-null    object \n",
      " 9   subtoken_strs_cloze    208 non-null    object \n",
      " 10  surprisal_buggy_cloze  208 non-null    float64\n",
      " 11  surprisal_fixed_cloze  208 non-null    float64\n",
      "dtypes: float64(4), object(8)\n",
      "memory usage: 19.6+ KB\n"
     ]
    }
   ],
   "source": [
    "all_results[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "864078fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame()\n",
    "for k, df in enumerate(all_results):\n",
    "    labels = []\n",
    "    surp_buggy = []\n",
    "    surp_fixed = []\n",
    "    surp_buggy_cloze = []\n",
    "    surp_fixed_cloze = []\n",
    "    for i, row in df.iterrows():\n",
    "        labels.append(row['novelty_label'])\n",
    "        surp_buggy.append(row['surprisal_buggy'])\n",
    "        surp_fixed.append(row['surprisal_fixed'])\n",
    "        surp_buggy_cloze.append(row['surprisal_buggy_cloze'])\n",
    "        surp_fixed_cloze.append(row['surprisal_fixed_cloze'])\n",
    "    df_analysis['labels'] = labels\n",
    "    df_analysis[f\"surprisal_buggy_{models_ids[k]}\"] = surp_buggy\n",
    "    df_analysis[f\"surprisal_fixed_{models_ids[k]}\"] = surp_fixed\n",
    "    df_analysis[f\"surprisal_buggy_cloze_{models_ids[k]}\"] = surp_buggy_cloze\n",
    "    df_analysis[f\"surprisal_fixed_cloze_{models_ids[k]}\"] = surp_fixed_cloze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1026ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   labels                                       208 non-null    object \n",
      " 1   surprisal_buggy_gpt2                         208 non-null    float64\n",
      " 2   surprisal_fixed_gpt2                         208 non-null    float64\n",
      " 3   surprisal_buggy_cloze_gpt2                   208 non-null    float64\n",
      " 4   surprisal_fixed_cloze_gpt2                   208 non-null    float64\n",
      " 5   surprisal_buggy_Llama-3.2-1B                 208 non-null    float64\n",
      " 6   surprisal_fixed_Llama-3.2-1B                 208 non-null    float64\n",
      " 7   surprisal_buggy_cloze_Llama-3.2-1B           208 non-null    float64\n",
      " 8   surprisal_fixed_cloze_Llama-3.2-1B           208 non-null    float64\n",
      " 9   surprisal_buggy_Llama-3.1-8B                 208 non-null    float64\n",
      " 10  surprisal_fixed_Llama-3.1-8B                 208 non-null    float64\n",
      " 11  surprisal_buggy_cloze_Llama-3.1-8B           208 non-null    float64\n",
      " 12  surprisal_fixed_cloze_Llama-3.1-8B           208 non-null    float64\n",
      " 13  surprisal_buggy_Llama-3.2-1B-Instruct        208 non-null    float64\n",
      " 14  surprisal_fixed_Llama-3.2-1B-Instruct        208 non-null    float64\n",
      " 15  surprisal_buggy_cloze_Llama-3.2-1B-Instruct  208 non-null    float64\n",
      " 16  surprisal_fixed_cloze_Llama-3.2-1B-Instruct  208 non-null    float64\n",
      " 17  surprisal_buggy_Qwen2.5-14B-Instruct         208 non-null    float64\n",
      " 18  surprisal_fixed_Qwen2.5-14B-Instruct         208 non-null    float64\n",
      " 19  surprisal_buggy_cloze_Qwen2.5-14B-Instruct   208 non-null    float64\n",
      " 20  surprisal_fixed_cloze_Qwen2.5-14B-Instruct   208 non-null    float64\n",
      " 21  surprisal_buggy_Qwen2.5-7B-Instruct          208 non-null    float64\n",
      " 22  surprisal_fixed_Qwen2.5-7B-Instruct          208 non-null    float64\n",
      " 23  surprisal_buggy_cloze_Qwen2.5-7B-Instruct    208 non-null    float64\n",
      " 24  surprisal_fixed_cloze_Qwen2.5-7B-Instruct    208 non-null    float64\n",
      " 25  surprisal_buggy_gpt2-xl                      208 non-null    float64\n",
      " 26  surprisal_fixed_gpt2-xl                      208 non-null    float64\n",
      " 27  surprisal_buggy_cloze_gpt2-xl                208 non-null    float64\n",
      " 28  surprisal_fixed_cloze_gpt2-xl                208 non-null    float64\n",
      " 29  surprisal_buggy_gpt2-medium                  208 non-null    float64\n",
      " 30  surprisal_fixed_gpt2-medium                  208 non-null    float64\n",
      " 31  surprisal_buggy_cloze_gpt2-medium            208 non-null    float64\n",
      " 32  surprisal_fixed_cloze_gpt2-medium            208 non-null    float64\n",
      " 33  surprisal_buggy_Llama-3.2-3B-Instruct        208 non-null    float64\n",
      " 34  surprisal_fixed_Llama-3.2-3B-Instruct        208 non-null    float64\n",
      " 35  surprisal_buggy_cloze_Llama-3.2-3B-Instruct  208 non-null    float64\n",
      " 36  surprisal_fixed_cloze_Llama-3.2-3B-Instruct  208 non-null    float64\n",
      " 37  surprisal_buggy_Qwen2.5-7B                   208 non-null    float64\n",
      " 38  surprisal_fixed_Qwen2.5-7B                   208 non-null    float64\n",
      " 39  surprisal_buggy_cloze_Qwen2.5-7B             208 non-null    float64\n",
      " 40  surprisal_fixed_cloze_Qwen2.5-7B             208 non-null    float64\n",
      " 41  surprisal_buggy_Llama-3.2-3B                 208 non-null    float64\n",
      " 42  surprisal_fixed_Llama-3.2-3B                 208 non-null    float64\n",
      " 43  surprisal_buggy_cloze_Llama-3.2-3B           208 non-null    float64\n",
      " 44  surprisal_fixed_cloze_Llama-3.2-3B           208 non-null    float64\n",
      " 45  surprisal_buggy_Llama-3.1-8B-Instruct        208 non-null    float64\n",
      " 46  surprisal_fixed_Llama-3.1-8B-Instruct        208 non-null    float64\n",
      " 47  surprisal_buggy_cloze_Llama-3.1-8B-Instruct  208 non-null    float64\n",
      " 48  surprisal_fixed_cloze_Llama-3.1-8B-Instruct  208 non-null    float64\n",
      " 49  surprisal_buggy_Qwen2.5-0.5B                 208 non-null    float64\n",
      " 50  surprisal_fixed_Qwen2.5-0.5B                 208 non-null    float64\n",
      " 51  surprisal_buggy_cloze_Qwen2.5-0.5B           208 non-null    float64\n",
      " 52  surprisal_fixed_cloze_Qwen2.5-0.5B           208 non-null    float64\n",
      " 53  surprisal_buggy_Qwen2.5-0.5B-Instruct        208 non-null    float64\n",
      " 54  surprisal_fixed_Qwen2.5-0.5B-Instruct        208 non-null    float64\n",
      " 55  surprisal_buggy_cloze_Qwen2.5-0.5B-Instruct  208 non-null    float64\n",
      " 56  surprisal_fixed_cloze_Qwen2.5-0.5B-Instruct  208 non-null    float64\n",
      " 57  surprisal_buggy_gpt2-large                   208 non-null    float64\n",
      " 58  surprisal_fixed_gpt2-large                   208 non-null    float64\n",
      " 59  surprisal_buggy_cloze_gpt2-large             208 non-null    float64\n",
      " 60  surprisal_fixed_cloze_gpt2-large             208 non-null    float64\n",
      " 61  surprisal_buggy_Qwen2.5-14B                  208 non-null    float64\n",
      " 62  surprisal_fixed_Qwen2.5-14B                  208 non-null    float64\n",
      " 63  surprisal_buggy_cloze_Qwen2.5-14B            208 non-null    float64\n",
      " 64  surprisal_fixed_cloze_Qwen2.5-14B            208 non-null    float64\n",
      "dtypes: float64(64), object(1)\n",
      "memory usage: 105.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad001a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprisal_buggy_gpt2</td>\n",
       "      <td>0.275888</td>\n",
       "      <td>0.637944</td>\n",
       "      <td>5.894364e-04</td>\n",
       "      <td>0.476211</td>\n",
       "      <td>0.275888</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprisal_buggy_Llama-3.2-1B</td>\n",
       "      <td>0.462278</td>\n",
       "      <td>0.731139</td>\n",
       "      <td>8.467884e-09</td>\n",
       "      <td>0.808066</td>\n",
       "      <td>0.462278</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprisal_buggy_Llama-3.1-8B</td>\n",
       "      <td>0.492419</td>\n",
       "      <td>0.746209</td>\n",
       "      <td>8.546854e-10</td>\n",
       "      <td>0.864563</td>\n",
       "      <td>0.492419</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisal_buggy_Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.460244</td>\n",
       "      <td>0.730122</td>\n",
       "      <td>9.836398e-09</td>\n",
       "      <td>0.780932</td>\n",
       "      <td>0.460244</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprisal_buggy_Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.479845</td>\n",
       "      <td>0.739922</td>\n",
       "      <td>2.262393e-09</td>\n",
       "      <td>0.776822</td>\n",
       "      <td>0.479845</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>surprisal_fixed_cloze_Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.520340</td>\n",
       "      <td>0.760170</td>\n",
       "      <td>9.031750e-11</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.520340</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-0.5B</td>\n",
       "      <td>0.349667</td>\n",
       "      <td>0.674834</td>\n",
       "      <td>1.326250e-05</td>\n",
       "      <td>0.650370</td>\n",
       "      <td>0.349667</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>0.336908</td>\n",
       "      <td>0.668454</td>\n",
       "      <td>2.707700e-05</td>\n",
       "      <td>0.617381</td>\n",
       "      <td>0.336908</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.255178</td>\n",
       "      <td>0.627589</td>\n",
       "      <td>1.481004e-03</td>\n",
       "      <td>0.483504</td>\n",
       "      <td>0.255178</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-14B</td>\n",
       "      <td>0.539386</td>\n",
       "      <td>0.769693</td>\n",
       "      <td>1.821719e-11</td>\n",
       "      <td>1.003791</td>\n",
       "      <td>0.539386</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feature  rank_biserial_r       auc  \\\n",
       "0                          surprisal_buggy_gpt2         0.275888  0.637944   \n",
       "1                  surprisal_buggy_Llama-3.2-1B         0.462278  0.731139   \n",
       "2                  surprisal_buggy_Llama-3.1-8B         0.492419  0.746209   \n",
       "3         surprisal_buggy_Llama-3.2-1B-Instruct         0.460244  0.730122   \n",
       "4          surprisal_buggy_Qwen2.5-14B-Instruct         0.479845  0.739922   \n",
       "..                                          ...              ...       ...   \n",
       "59  surprisal_fixed_cloze_Llama-3.1-8B-Instruct         0.520340  0.760170   \n",
       "60           surprisal_fixed_cloze_Qwen2.5-0.5B         0.349667  0.674834   \n",
       "61  surprisal_fixed_cloze_Qwen2.5-0.5B-Instruct         0.336908  0.668454   \n",
       "62             surprisal_fixed_cloze_gpt2-large         0.255178  0.627589   \n",
       "63            surprisal_fixed_cloze_Qwen2.5-14B         0.539386  0.769693   \n",
       "\n",
       "            mw_p  cohens_d  cliffs_delta cliffs_size  \n",
       "0   5.894364e-04  0.476211      0.275888       small  \n",
       "1   8.467884e-09  0.808066      0.462278      medium  \n",
       "2   8.546854e-10  0.864563      0.492419       large  \n",
       "3   9.836398e-09  0.780932      0.460244      medium  \n",
       "4   2.262393e-09  0.776822      0.479845       large  \n",
       "..           ...       ...           ...         ...  \n",
       "59  9.031750e-11  0.971510      0.520340       large  \n",
       "60  1.326250e-05  0.650370      0.349667      medium  \n",
       "61  2.707700e-05  0.617381      0.336908      medium  \n",
       "62  1.481004e-03  0.483504      0.255178       small  \n",
       "63  1.821719e-11  1.003791      0.539386       large  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df = get_corr_stats(df_analysis, binary=True, feats=[f\"surprisal_buggy_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_{mid}\" for mid in models_ids] + [f\"surprisal_buggy_cloze_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_cloze_{mid}\" for mid in models_ids], score_col=\"score\", binary_col='labels')\n",
    "corr_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee0df6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>surprisal_fixed_gpt2</td>\n",
       "      <td>0.276442</td>\n",
       "      <td>0.638221</td>\n",
       "      <td>5.745739e-04</td>\n",
       "      <td>0.475562</td>\n",
       "      <td>0.276442</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>surprisal_fixed_gpt2-xl</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>0.706823</td>\n",
       "      <td>2.564672e-07</td>\n",
       "      <td>0.748590</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>surprisal_fixed_gpt2-medium</td>\n",
       "      <td>0.361871</td>\n",
       "      <td>0.680936</td>\n",
       "      <td>6.550535e-06</td>\n",
       "      <td>0.633297</td>\n",
       "      <td>0.361871</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>surprisal_fixed_gpt2-large</td>\n",
       "      <td>0.397374</td>\n",
       "      <td>0.698687</td>\n",
       "      <td>7.415136e-07</td>\n",
       "      <td>0.698448</td>\n",
       "      <td>0.397374</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2</td>\n",
       "      <td>0.199889</td>\n",
       "      <td>0.599945</td>\n",
       "      <td>1.279296e-02</td>\n",
       "      <td>0.345545</td>\n",
       "      <td>0.199889</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-xl</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>0.626757</td>\n",
       "      <td>1.590496e-03</td>\n",
       "      <td>0.456952</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-medium</td>\n",
       "      <td>0.243713</td>\n",
       "      <td>0.621857</td>\n",
       "      <td>2.401120e-03</td>\n",
       "      <td>0.441738</td>\n",
       "      <td>0.243713</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.255178</td>\n",
       "      <td>0.627589</td>\n",
       "      <td>1.481004e-03</td>\n",
       "      <td>0.483504</td>\n",
       "      <td>0.255178</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  rank_biserial_r       auc  \\\n",
       "16               surprisal_fixed_gpt2         0.276442  0.638221   \n",
       "22            surprisal_fixed_gpt2-xl         0.413646  0.706823   \n",
       "23        surprisal_fixed_gpt2-medium         0.361871  0.680936   \n",
       "30         surprisal_fixed_gpt2-large         0.397374  0.698687   \n",
       "48         surprisal_fixed_cloze_gpt2         0.199889  0.599945   \n",
       "54      surprisal_fixed_cloze_gpt2-xl         0.253513  0.626757   \n",
       "55  surprisal_fixed_cloze_gpt2-medium         0.243713  0.621857   \n",
       "62   surprisal_fixed_cloze_gpt2-large         0.255178  0.627589   \n",
       "\n",
       "            mw_p  cohens_d  cliffs_delta cliffs_size  \n",
       "16  5.745739e-04  0.475562      0.276442       small  \n",
       "22  2.564672e-07  0.748590      0.413646      medium  \n",
       "23  6.550535e-06  0.633297      0.361871      medium  \n",
       "30  7.415136e-07  0.698448      0.397374      medium  \n",
       "48  1.279296e-02  0.345545      0.199889       small  \n",
       "54  1.590496e-03  0.456952      0.253513       small  \n",
       "55  2.401120e-03  0.441738      0.243713       small  \n",
       "62  1.481004e-03  0.483504      0.255178       small  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df[(corr_res_df['feature'].str.contains(\"surprisal_fixed\")) & (corr_res_df['feature'].str.contains(\"gpt2\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f7bba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ids_ordered = [\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "        \n",
    "    'Llama-3.2-1B',\n",
    "    'Llama-3.2-1B-Instruct',\n",
    "    'Llama-3.2-3B',\n",
    "    'Llama-3.2-3B-Instruct',\n",
    "    'Llama-3.1-8B',\n",
    "    'Llama-3.1-8B-Instruct',    \n",
    "\n",
    "    'Qwen2.5-0.5B',    \n",
    "    'Qwen2.5-0.5B-Instruct',\n",
    "    'Qwen2.5-7B',\n",
    "    'Qwen2.5-7B-Instruct',    \n",
    "    'Qwen2.5-14B',    \n",
    "    'Qwen2.5-14B-Instruct',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76978efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = []\n",
    "auc = []\n",
    "mw_p = []\n",
    "c_delta = []\n",
    "cloze_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    rb.append(corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    auc.append(corr_res_df[corr_res_df['feature']==feat].auc.item())\n",
    "    mw_p.append(corr_res_df[corr_res_df['feature']==feat].mw_p.item())\n",
    "    c_delta.append(corr_res_df[corr_res_df['feature']==feat].cliffs_delta.item())\n",
    "    feat_cloze = f\"surprisal_fixed_cloze_{m}\"\n",
    "    cloze_gain.append(corr_res_df[corr_res_df['feature']==feat_cloze].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e8e0eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rank_biserial</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cloze_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.276442</td>\n",
       "      <td>0.638221</td>\n",
       "      <td>5.745739e-04</td>\n",
       "      <td>0.276442</td>\n",
       "      <td>-0.076553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.361871</td>\n",
       "      <td>0.680936</td>\n",
       "      <td>6.550535e-06</td>\n",
       "      <td>0.361871</td>\n",
       "      <td>-0.118158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>0.397374</td>\n",
       "      <td>0.698687</td>\n",
       "      <td>7.415136e-07</td>\n",
       "      <td>0.397374</td>\n",
       "      <td>-0.142197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>0.706823</td>\n",
       "      <td>2.564672e-07</td>\n",
       "      <td>0.413646</td>\n",
       "      <td>-0.160133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.449519</td>\n",
       "      <td>0.724760</td>\n",
       "      <td>2.144836e-08</td>\n",
       "      <td>0.449519</td>\n",
       "      <td>-0.132581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.453957</td>\n",
       "      <td>0.726979</td>\n",
       "      <td>1.556742e-08</td>\n",
       "      <td>0.453957</td>\n",
       "      <td>-0.024408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.450814</td>\n",
       "      <td>0.725407</td>\n",
       "      <td>1.954043e-08</td>\n",
       "      <td>0.450814</td>\n",
       "      <td>0.003143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.393306</td>\n",
       "      <td>0.696653</td>\n",
       "      <td>9.609318e-07</td>\n",
       "      <td>0.393306</td>\n",
       "      <td>0.047152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.483358</td>\n",
       "      <td>0.741679</td>\n",
       "      <td>1.727791e-09</td>\n",
       "      <td>0.483358</td>\n",
       "      <td>0.025148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.460244</td>\n",
       "      <td>0.730122</td>\n",
       "      <td>9.836398e-09</td>\n",
       "      <td>0.460244</td>\n",
       "      <td>0.060096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>0.374260</td>\n",
       "      <td>0.687130</td>\n",
       "      <td>3.129049e-06</td>\n",
       "      <td>0.374260</td>\n",
       "      <td>-0.024593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.687870</td>\n",
       "      <td>2.860450e-06</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>-0.038831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>0.493898</td>\n",
       "      <td>0.746949</td>\n",
       "      <td>7.610009e-10</td>\n",
       "      <td>0.493898</td>\n",
       "      <td>0.024038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.404586</td>\n",
       "      <td>0.702293</td>\n",
       "      <td>4.654848e-07</td>\n",
       "      <td>0.404586</td>\n",
       "      <td>0.090791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>0.504068</td>\n",
       "      <td>0.752034</td>\n",
       "      <td>3.394974e-10</td>\n",
       "      <td>0.504068</td>\n",
       "      <td>0.035318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.467456</td>\n",
       "      <td>0.733728</td>\n",
       "      <td>5.766842e-09</td>\n",
       "      <td>0.467456</td>\n",
       "      <td>0.045858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  rank_biserial       auc          mw_p  \\\n",
       "0                    gpt2       0.276442  0.638221  5.745739e-04   \n",
       "1             gpt2-medium       0.361871  0.680936  6.550535e-06   \n",
       "2              gpt2-large       0.397374  0.698687  7.415136e-07   \n",
       "3                 gpt2-xl       0.413646  0.706823  2.564672e-07   \n",
       "4            Llama-3.2-1B       0.449519  0.724760  2.144836e-08   \n",
       "5   Llama-3.2-1B-Instruct       0.453957  0.726979  1.556742e-08   \n",
       "6            Llama-3.2-3B       0.450814  0.725407  1.954043e-08   \n",
       "7   Llama-3.2-3B-Instruct       0.393306  0.696653  9.609318e-07   \n",
       "8            Llama-3.1-8B       0.483358  0.741679  1.727791e-09   \n",
       "9   Llama-3.1-8B-Instruct       0.460244  0.730122  9.836398e-09   \n",
       "10           Qwen2.5-0.5B       0.374260  0.687130  3.129049e-06   \n",
       "11  Qwen2.5-0.5B-Instruct       0.375740  0.687870  2.860450e-06   \n",
       "12             Qwen2.5-7B       0.493898  0.746949  7.610009e-10   \n",
       "13    Qwen2.5-7B-Instruct       0.404586  0.702293  4.654848e-07   \n",
       "14            Qwen2.5-14B       0.504068  0.752034  3.394974e-10   \n",
       "15   Qwen2.5-14B-Instruct       0.467456  0.733728  5.766842e-09   \n",
       "\n",
       "    cliffs_delta  cloze_gain  \n",
       "0       0.276442   -0.076553  \n",
       "1       0.361871   -0.118158  \n",
       "2       0.397374   -0.142197  \n",
       "3       0.413646   -0.160133  \n",
       "4       0.449519   -0.132581  \n",
       "5       0.453957   -0.024408  \n",
       "6       0.450814    0.003143  \n",
       "7       0.393306    0.047152  \n",
       "8       0.483358    0.025148  \n",
       "9       0.460244    0.060096  \n",
       "10      0.374260   -0.024593  \n",
       "11      0.375740   -0.038831  \n",
       "12      0.493898    0.024038  \n",
       "13      0.404586    0.090791  \n",
       "14      0.504068    0.035318  \n",
       "15      0.467456    0.045858  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lai_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"rank_biserial\": rb,\n",
    "    \"auc\": auc,\n",
    "    \"mw_p\": mw_p,\n",
    "    \"cliffs_delta\": c_delta,\n",
    "    \"cloze_gain\": cloze_gain\n",
    "})\n",
    "lai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4c376e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    feat_instruct = f\"{feat}-Instruct\"\n",
    "    if feat_instruct in corr_res_df['feature'].values:\n",
    "        instruct_gain.append(corr_res_df[corr_res_df['feature']==feat_instruct].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    else:\n",
    "        instruct_gain.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae2e9dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>instruct_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.004438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>-0.057507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>-0.023114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>-0.089312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>-0.036612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  instruct_gain\n",
       "0                    gpt2            NaN\n",
       "1             gpt2-medium            NaN\n",
       "2              gpt2-large            NaN\n",
       "3                 gpt2-xl            NaN\n",
       "4            Llama-3.2-1B       0.004438\n",
       "5   Llama-3.2-1B-Instruct            NaN\n",
       "6            Llama-3.2-3B      -0.057507\n",
       "7   Llama-3.2-3B-Instruct            NaN\n",
       "8            Llama-3.1-8B      -0.023114\n",
       "9   Llama-3.1-8B-Instruct            NaN\n",
       "10           Qwen2.5-0.5B       0.001479\n",
       "11  Qwen2.5-0.5B-Instruct            NaN\n",
       "12             Qwen2.5-7B      -0.089312\n",
       "13    Qwen2.5-7B-Instruct            NaN\n",
       "14            Qwen2.5-14B      -0.036612\n",
       "15   Qwen2.5-14B-Instruct            NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lai_2_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"instruct_gain\": instruct_gain\n",
    "})\n",
    "lai_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d55b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca081e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a7b1eba",
   "metadata": {},
   "source": [
    "# GPT-4o results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3934b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-4o-METANOV_mod_openai-community_gpt2-xl_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_openai-community_gpt2_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_Qwen_Qwen2.5-0.5B_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_Qwen_Qwen2.5-0.5B-Instruct_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_meta-llama_Llama-3.1-8B_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_Qwen_Qwen2.5-7B_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_meta-llama_Llama-3.2-3B_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_Qwen_Qwen2.5-14B_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_meta-llama_Llama-3.2-1B-Instruct_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_meta-llama_Llama-3.1-8B-Instruct_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_meta-llama_Llama-3.2-1B_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_openai-community_gpt2-large_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_openai-community_gpt2-medium_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_meta-llama_Llama-3.2-3B-Instruct_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_Qwen_Qwen2.5-14B-Instruct_cloze_pimentel.parquet...\n",
      "Loading GPT-4o-METANOV_mod_Qwen_Qwen2.5-7B-Instruct_cloze_pimentel.parquet...\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "models_ids = []\n",
    "for f in os.listdir(\"results\"):\n",
    "    if f.endswith(\".parquet\") and \"GPT\" in f:\n",
    "        print(f\"Loading {f}...\")\n",
    "        df_part = pd.read_parquet(os.path.join(\"results\", f))\n",
    "        all_results.append(df_part)\n",
    "        models_ids.append(f.split(\"_\")[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb70a3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt2-xl',\n",
       " 'gpt2',\n",
       " 'Qwen2.5-0.5B',\n",
       " 'Qwen2.5-0.5B-Instruct',\n",
       " 'Llama-3.1-8B',\n",
       " 'Qwen2.5-7B',\n",
       " 'Llama-3.2-3B',\n",
       " 'Qwen2.5-14B',\n",
       " 'Llama-3.2-1B-Instruct',\n",
       " 'Llama-3.1-8B-Instruct',\n",
       " 'Llama-3.2-1B',\n",
       " 'gpt2-large',\n",
       " 'gpt2-medium',\n",
       " 'Llama-3.2-3B-Instruct',\n",
       " 'Qwen2.5-14B-Instruct',\n",
       " 'Qwen2.5-7B-Instruct']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4f3636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   sentence               200 non-null    object \n",
      " 1   target_word            200 non-null    object \n",
      " 2   novelty_label          200 non-null    object \n",
      " 3   offsets                200 non-null    object \n",
      " 4   subtoken_ids           200 non-null    object \n",
      " 5   subtoken_strs          200 non-null    object \n",
      " 6   surprisal_buggy        200 non-null    float64\n",
      " 7   surprisal_fixed        200 non-null    float64\n",
      " 8   subtoken_ids_cloze     200 non-null    object \n",
      " 9   subtoken_strs_cloze    200 non-null    object \n",
      " 10  surprisal_buggy_cloze  200 non-null    float64\n",
      " 11  surprisal_fixed_cloze  200 non-null    float64\n",
      "dtypes: float64(4), object(8)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "all_results[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "503c3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.DataFrame()\n",
    "for k, df in enumerate(all_results):\n",
    "    labels = []\n",
    "    surp_buggy = []\n",
    "    surp_fixed = []\n",
    "    surp_buggy_cloze = []\n",
    "    surp_fixed_cloze = []\n",
    "    for i, row in df.iterrows():\n",
    "        labels.append(row['novelty_label'])\n",
    "        surp_buggy.append(row['surprisal_buggy'])\n",
    "        surp_fixed.append(row['surprisal_fixed'])\n",
    "        surp_buggy_cloze.append(row['surprisal_buggy_cloze'])\n",
    "        surp_fixed_cloze.append(row['surprisal_fixed_cloze'])\n",
    "    df_analysis['labels'] = labels\n",
    "    df_analysis[f\"surprisal_buggy_{models_ids[k]}\"] = surp_buggy\n",
    "    df_analysis[f\"surprisal_fixed_{models_ids[k]}\"] = surp_fixed\n",
    "    df_analysis[f\"surprisal_buggy_cloze_{models_ids[k]}\"] = surp_buggy_cloze\n",
    "    df_analysis[f\"surprisal_fixed_cloze_{models_ids[k]}\"] = surp_fixed_cloze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd852d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 65 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   labels                                       200 non-null    object \n",
      " 1   surprisal_buggy_gpt2-xl                      200 non-null    float64\n",
      " 2   surprisal_fixed_gpt2-xl                      200 non-null    float64\n",
      " 3   surprisal_buggy_cloze_gpt2-xl                200 non-null    float64\n",
      " 4   surprisal_fixed_cloze_gpt2-xl                200 non-null    float64\n",
      " 5   surprisal_buggy_gpt2                         200 non-null    float64\n",
      " 6   surprisal_fixed_gpt2                         200 non-null    float64\n",
      " 7   surprisal_buggy_cloze_gpt2                   200 non-null    float64\n",
      " 8   surprisal_fixed_cloze_gpt2                   200 non-null    float64\n",
      " 9   surprisal_buggy_Qwen2.5-0.5B                 200 non-null    float64\n",
      " 10  surprisal_fixed_Qwen2.5-0.5B                 200 non-null    float64\n",
      " 11  surprisal_buggy_cloze_Qwen2.5-0.5B           200 non-null    float64\n",
      " 12  surprisal_fixed_cloze_Qwen2.5-0.5B           200 non-null    float64\n",
      " 13  surprisal_buggy_Qwen2.5-0.5B-Instruct        200 non-null    float64\n",
      " 14  surprisal_fixed_Qwen2.5-0.5B-Instruct        200 non-null    float64\n",
      " 15  surprisal_buggy_cloze_Qwen2.5-0.5B-Instruct  200 non-null    float64\n",
      " 16  surprisal_fixed_cloze_Qwen2.5-0.5B-Instruct  200 non-null    float64\n",
      " 17  surprisal_buggy_Llama-3.1-8B                 200 non-null    float64\n",
      " 18  surprisal_fixed_Llama-3.1-8B                 200 non-null    float64\n",
      " 19  surprisal_buggy_cloze_Llama-3.1-8B           200 non-null    float64\n",
      " 20  surprisal_fixed_cloze_Llama-3.1-8B           200 non-null    float64\n",
      " 21  surprisal_buggy_Qwen2.5-7B                   200 non-null    float64\n",
      " 22  surprisal_fixed_Qwen2.5-7B                   200 non-null    float64\n",
      " 23  surprisal_buggy_cloze_Qwen2.5-7B             200 non-null    float64\n",
      " 24  surprisal_fixed_cloze_Qwen2.5-7B             200 non-null    float64\n",
      " 25  surprisal_buggy_Llama-3.2-3B                 200 non-null    float64\n",
      " 26  surprisal_fixed_Llama-3.2-3B                 200 non-null    float64\n",
      " 27  surprisal_buggy_cloze_Llama-3.2-3B           200 non-null    float64\n",
      " 28  surprisal_fixed_cloze_Llama-3.2-3B           200 non-null    float64\n",
      " 29  surprisal_buggy_Qwen2.5-14B                  200 non-null    float64\n",
      " 30  surprisal_fixed_Qwen2.5-14B                  200 non-null    float64\n",
      " 31  surprisal_buggy_cloze_Qwen2.5-14B            200 non-null    float64\n",
      " 32  surprisal_fixed_cloze_Qwen2.5-14B            200 non-null    float64\n",
      " 33  surprisal_buggy_Llama-3.2-1B-Instruct        200 non-null    float64\n",
      " 34  surprisal_fixed_Llama-3.2-1B-Instruct        200 non-null    float64\n",
      " 35  surprisal_buggy_cloze_Llama-3.2-1B-Instruct  200 non-null    float64\n",
      " 36  surprisal_fixed_cloze_Llama-3.2-1B-Instruct  200 non-null    float64\n",
      " 37  surprisal_buggy_Llama-3.1-8B-Instruct        200 non-null    float64\n",
      " 38  surprisal_fixed_Llama-3.1-8B-Instruct        200 non-null    float64\n",
      " 39  surprisal_buggy_cloze_Llama-3.1-8B-Instruct  200 non-null    float64\n",
      " 40  surprisal_fixed_cloze_Llama-3.1-8B-Instruct  200 non-null    float64\n",
      " 41  surprisal_buggy_Llama-3.2-1B                 200 non-null    float64\n",
      " 42  surprisal_fixed_Llama-3.2-1B                 200 non-null    float64\n",
      " 43  surprisal_buggy_cloze_Llama-3.2-1B           200 non-null    float64\n",
      " 44  surprisal_fixed_cloze_Llama-3.2-1B           200 non-null    float64\n",
      " 45  surprisal_buggy_gpt2-large                   200 non-null    float64\n",
      " 46  surprisal_fixed_gpt2-large                   200 non-null    float64\n",
      " 47  surprisal_buggy_cloze_gpt2-large             200 non-null    float64\n",
      " 48  surprisal_fixed_cloze_gpt2-large             200 non-null    float64\n",
      " 49  surprisal_buggy_gpt2-medium                  200 non-null    float64\n",
      " 50  surprisal_fixed_gpt2-medium                  200 non-null    float64\n",
      " 51  surprisal_buggy_cloze_gpt2-medium            200 non-null    float64\n",
      " 52  surprisal_fixed_cloze_gpt2-medium            200 non-null    float64\n",
      " 53  surprisal_buggy_Llama-3.2-3B-Instruct        200 non-null    float64\n",
      " 54  surprisal_fixed_Llama-3.2-3B-Instruct        200 non-null    float64\n",
      " 55  surprisal_buggy_cloze_Llama-3.2-3B-Instruct  200 non-null    float64\n",
      " 56  surprisal_fixed_cloze_Llama-3.2-3B-Instruct  200 non-null    float64\n",
      " 57  surprisal_buggy_Qwen2.5-14B-Instruct         200 non-null    float64\n",
      " 58  surprisal_fixed_Qwen2.5-14B-Instruct         200 non-null    float64\n",
      " 59  surprisal_buggy_cloze_Qwen2.5-14B-Instruct   200 non-null    float64\n",
      " 60  surprisal_fixed_cloze_Qwen2.5-14B-Instruct   200 non-null    float64\n",
      " 61  surprisal_buggy_Qwen2.5-7B-Instruct          200 non-null    float64\n",
      " 62  surprisal_fixed_Qwen2.5-7B-Instruct          200 non-null    float64\n",
      " 63  surprisal_buggy_cloze_Qwen2.5-7B-Instruct    200 non-null    float64\n",
      " 64  surprisal_fixed_cloze_Qwen2.5-7B-Instruct    200 non-null    float64\n",
      "dtypes: float64(64), object(1)\n",
      "memory usage: 101.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0455e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surprisal_buggy_gpt2-xl</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.78335</td>\n",
       "      <td>4.449074e-12</td>\n",
       "      <td>1.130037</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surprisal_buggy_gpt2</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.74610</td>\n",
       "      <td>1.832929e-09</td>\n",
       "      <td>0.988014</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surprisal_buggy_Qwen2.5-0.5B</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.68045</td>\n",
       "      <td>1.043881e-05</td>\n",
       "      <td>0.612829</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprisal_buggy_Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.69305</td>\n",
       "      <td>2.408269e-06</td>\n",
       "      <td>0.671574</td>\n",
       "      <td>0.3861</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surprisal_buggy_Llama-3.1-8B</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.76860</td>\n",
       "      <td>5.318944e-11</td>\n",
       "      <td>1.058400</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>0.68910</td>\n",
       "      <td>3.851729e-06</td>\n",
       "      <td>0.654295</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-medium</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.65840</td>\n",
       "      <td>1.092350e-04</td>\n",
       "      <td>0.587034</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>surprisal_fixed_cloze_Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>0.75980</td>\n",
       "      <td>2.199787e-10</td>\n",
       "      <td>0.945969</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>0.76220</td>\n",
       "      <td>1.500308e-10</td>\n",
       "      <td>1.058946</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>surprisal_fixed_cloze_Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.70580</td>\n",
       "      <td>4.975048e-07</td>\n",
       "      <td>0.736094</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feature  rank_biserial_r      auc  \\\n",
       "0                       surprisal_buggy_gpt2-xl           0.5667  0.78335   \n",
       "1                          surprisal_buggy_gpt2           0.4922  0.74610   \n",
       "2                  surprisal_buggy_Qwen2.5-0.5B           0.3609  0.68045   \n",
       "3         surprisal_buggy_Qwen2.5-0.5B-Instruct           0.3861  0.69305   \n",
       "4                  surprisal_buggy_Llama-3.1-8B           0.5372  0.76860   \n",
       "..                                          ...              ...      ...   \n",
       "59             surprisal_fixed_cloze_gpt2-large           0.3782  0.68910   \n",
       "60            surprisal_fixed_cloze_gpt2-medium           0.3168  0.65840   \n",
       "61  surprisal_fixed_cloze_Llama-3.2-3B-Instruct           0.5196  0.75980   \n",
       "62   surprisal_fixed_cloze_Qwen2.5-14B-Instruct           0.5244  0.76220   \n",
       "63    surprisal_fixed_cloze_Qwen2.5-7B-Instruct           0.4116  0.70580   \n",
       "\n",
       "            mw_p  cohens_d  cliffs_delta cliffs_size  \n",
       "0   4.449074e-12  1.130037        0.5667       large  \n",
       "1   1.832929e-09  0.988014        0.4922       large  \n",
       "2   1.043881e-05  0.612829        0.3609      medium  \n",
       "3   2.408269e-06  0.671574        0.3861      medium  \n",
       "4   5.318944e-11  1.058400        0.5372       large  \n",
       "..           ...       ...           ...         ...  \n",
       "59  3.851729e-06  0.654295        0.3782      medium  \n",
       "60  1.092350e-04  0.587034        0.3168       small  \n",
       "61  2.199787e-10  0.945969        0.5196       large  \n",
       "62  1.500308e-10  1.058946        0.5244       large  \n",
       "63  4.975048e-07  0.736094        0.4116      medium  \n",
       "\n",
       "[64 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df = get_corr_stats(df_analysis, binary=True, feats=[f\"surprisal_buggy_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_{mid}\" for mid in models_ids] + [f\"surprisal_buggy_cloze_{mid}\" for mid in models_ids] + [f\"surprisal_fixed_cloze_{mid}\" for mid in models_ids], score_col=\"score\", binary_col='labels')\n",
    "corr_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e474dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rank_biserial_r</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cliffs_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>surprisal_fixed_gpt2-xl</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>0.79355</td>\n",
       "      <td>7.425936e-13</td>\n",
       "      <td>1.175363</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>surprisal_fixed_gpt2</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.75550</td>\n",
       "      <td>4.330087e-10</td>\n",
       "      <td>1.029852</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>surprisal_fixed_gpt2-large</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.81445</td>\n",
       "      <td>1.565953e-14</td>\n",
       "      <td>1.283981</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>surprisal_fixed_gpt2-medium</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.79310</td>\n",
       "      <td>8.046910e-13</td>\n",
       "      <td>1.158512</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-xl</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.65310</td>\n",
       "      <td>1.843084e-04</td>\n",
       "      <td>0.507835</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2</td>\n",
       "      <td>0.3442</td>\n",
       "      <td>0.67210</td>\n",
       "      <td>2.624122e-05</td>\n",
       "      <td>0.579120</td>\n",
       "      <td>0.3442</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-large</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>0.68910</td>\n",
       "      <td>3.851729e-06</td>\n",
       "      <td>0.654295</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>surprisal_fixed_cloze_gpt2-medium</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.65840</td>\n",
       "      <td>1.092350e-04</td>\n",
       "      <td>0.587034</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  rank_biserial_r      auc          mw_p  \\\n",
       "16            surprisal_fixed_gpt2-xl           0.5871  0.79355  7.425936e-13   \n",
       "17               surprisal_fixed_gpt2           0.5110  0.75550  4.330087e-10   \n",
       "27         surprisal_fixed_gpt2-large           0.6289  0.81445  1.565953e-14   \n",
       "28        surprisal_fixed_gpt2-medium           0.5862  0.79310  8.046910e-13   \n",
       "48      surprisal_fixed_cloze_gpt2-xl           0.3062  0.65310  1.843084e-04   \n",
       "49         surprisal_fixed_cloze_gpt2           0.3442  0.67210  2.624122e-05   \n",
       "59   surprisal_fixed_cloze_gpt2-large           0.3782  0.68910  3.851729e-06   \n",
       "60  surprisal_fixed_cloze_gpt2-medium           0.3168  0.65840  1.092350e-04   \n",
       "\n",
       "    cohens_d  cliffs_delta cliffs_size  \n",
       "16  1.175363        0.5871       large  \n",
       "17  1.029852        0.5110       large  \n",
       "27  1.283981        0.6289       large  \n",
       "28  1.158512        0.5862       large  \n",
       "48  0.507835        0.3062       small  \n",
       "49  0.579120        0.3442      medium  \n",
       "59  0.654295        0.3782      medium  \n",
       "60  0.587034        0.3168       small  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_df[(corr_res_df['feature'].str.contains(\"surprisal_fixed\")) & (corr_res_df['feature'].str.contains(\"gpt\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "640e7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ids_ordered = [\n",
    "    'gpt2',\n",
    "    'gpt2-medium',\n",
    "    'gpt2-large',\n",
    "    'gpt2-xl',\n",
    "        \n",
    "    'Llama-3.2-1B',\n",
    "    'Llama-3.2-1B-Instruct',\n",
    "    'Llama-3.2-3B',\n",
    "    'Llama-3.2-3B-Instruct',\n",
    "    'Llama-3.1-8B',\n",
    "    'Llama-3.1-8B-Instruct',    \n",
    "\n",
    "    'Qwen2.5-0.5B',    \n",
    "    'Qwen2.5-0.5B-Instruct',\n",
    "    'Qwen2.5-7B',\n",
    "    'Qwen2.5-7B-Instruct',    \n",
    "    'Qwen2.5-14B',    \n",
    "    'Qwen2.5-14B-Instruct',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7510d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = []\n",
    "auc = []\n",
    "mw_p = []\n",
    "c_delta = []\n",
    "cloze_gain = []\n",
    "instruct_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    rb.append(corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    auc.append(corr_res_df[corr_res_df['feature']==feat].auc.item())\n",
    "    mw_p.append(corr_res_df[corr_res_df['feature']==feat].mw_p.item())\n",
    "    c_delta.append(corr_res_df[corr_res_df['feature']==feat].cliffs_delta.item())\n",
    "    feat_cloze = f\"surprisal_fixed_cloze_{m}\"\n",
    "    cloze_gain.append(corr_res_df[corr_res_df['feature']==feat_cloze].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbbcf806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rank_biserial</th>\n",
       "      <th>auc</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>cliffs_delta</th>\n",
       "      <th>cloze_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.75550</td>\n",
       "      <td>4.330087e-10</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>-0.1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.79310</td>\n",
       "      <td>8.046910e-13</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>-0.2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.81445</td>\n",
       "      <td>1.565953e-14</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>-0.2507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>0.79355</td>\n",
       "      <td>7.425936e-13</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>-0.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>0.75385</td>\n",
       "      <td>5.598870e-10</td>\n",
       "      <td>0.5077</td>\n",
       "      <td>-0.1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.72815</td>\n",
       "      <td>2.498490e-08</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>-0.1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>4.432672e-10</td>\n",
       "      <td>0.5107</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.4549</td>\n",
       "      <td>0.72745</td>\n",
       "      <td>2.755964e-08</td>\n",
       "      <td>0.4549</td>\n",
       "      <td>0.0647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.77840</td>\n",
       "      <td>1.037689e-11</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.75280</td>\n",
       "      <td>6.588538e-10</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>0.69095</td>\n",
       "      <td>3.094693e-06</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>0.0615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.70200</td>\n",
       "      <td>8.038694e-07</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.0696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.73445</td>\n",
       "      <td>1.020382e-08</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.66590</td>\n",
       "      <td>5.070346e-05</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.0798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>0.5362</td>\n",
       "      <td>0.76810</td>\n",
       "      <td>5.772758e-11</td>\n",
       "      <td>0.5362</td>\n",
       "      <td>0.0688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.69820</td>\n",
       "      <td>1.288128e-06</td>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  rank_biserial      auc          mw_p  cliffs_delta  \\\n",
       "0                    gpt2         0.5110  0.75550  4.330087e-10        0.5110   \n",
       "1             gpt2-medium         0.5862  0.79310  8.046910e-13        0.5862   \n",
       "2              gpt2-large         0.6289  0.81445  1.565953e-14        0.6289   \n",
       "3                 gpt2-xl         0.5871  0.79355  7.425936e-13        0.5871   \n",
       "4            Llama-3.2-1B         0.5077  0.75385  5.598870e-10        0.5077   \n",
       "5   Llama-3.2-1B-Instruct         0.4563  0.72815  2.498490e-08        0.4563   \n",
       "6            Llama-3.2-3B         0.5107  0.75535  4.432672e-10        0.5107   \n",
       "7   Llama-3.2-3B-Instruct         0.4549  0.72745  2.755964e-08        0.4549   \n",
       "8            Llama-3.1-8B         0.5568  0.77840  1.037689e-11        0.5568   \n",
       "9   Llama-3.1-8B-Instruct         0.5056  0.75280  6.588538e-10        0.5056   \n",
       "10           Qwen2.5-0.5B         0.3819  0.69095  3.094693e-06        0.3819   \n",
       "11  Qwen2.5-0.5B-Instruct         0.4040  0.70200  8.038694e-07        0.4040   \n",
       "12             Qwen2.5-7B         0.4689  0.73445  1.020382e-08        0.4689   \n",
       "13    Qwen2.5-7B-Instruct         0.3318  0.66590  5.070346e-05        0.3318   \n",
       "14            Qwen2.5-14B         0.5362  0.76810  5.772758e-11        0.5362   \n",
       "15   Qwen2.5-14B-Instruct         0.3964  0.69820  1.288128e-06        0.3964   \n",
       "\n",
       "    cloze_gain  \n",
       "0      -0.1668  \n",
       "1      -0.2694  \n",
       "2      -0.2507  \n",
       "3      -0.2809  \n",
       "4      -0.1569  \n",
       "5      -0.1025  \n",
       "6       0.0071  \n",
       "7       0.0647  \n",
       "8       0.1270  \n",
       "9       0.1090  \n",
       "10      0.0615  \n",
       "11      0.0696  \n",
       "12      0.1285  \n",
       "13      0.0798  \n",
       "14      0.0688  \n",
       "15      0.1280  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_t_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"rank_biserial\": rb,\n",
    "    \"auc\": auc,\n",
    "    \"mw_p\": mw_p,\n",
    "    \"cliffs_delta\": c_delta,\n",
    "    \"cloze_gain\": cloze_gain\n",
    "})\n",
    "gpt_t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37b68fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_gain = []\n",
    "for m in models_ids_ordered:\n",
    "    feat = f\"surprisal_fixed_{m}\"\n",
    "    feat_instruct = f\"{feat}-Instruct\"\n",
    "    if feat_instruct in corr_res_df['feature'].values:\n",
    "        instruct_gain.append(corr_res_df[corr_res_df['feature']==feat_instruct].rank_biserial_r.item() - corr_res_df[corr_res_df['feature']==feat].rank_biserial_r.item())\n",
    "    else:\n",
    "        instruct_gain.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1474dab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>instruct_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-large</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-3.2-1B</td>\n",
       "      <td>-0.0514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-3.2-1B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-3.2-3B</td>\n",
       "      <td>-0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Llama-3.1-8B</td>\n",
       "      <td>-0.0512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llama-3.1-8B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qwen2.5-0.5B</td>\n",
       "      <td>0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qwen2.5-0.5B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qwen2.5-7B</td>\n",
       "      <td>-0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qwen2.5-7B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qwen2.5-14B</td>\n",
       "      <td>-0.1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qwen2.5-14B-Instruct</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  instruct_gain\n",
       "0                    gpt2            NaN\n",
       "1             gpt2-medium            NaN\n",
       "2              gpt2-large            NaN\n",
       "3                 gpt2-xl            NaN\n",
       "4            Llama-3.2-1B        -0.0514\n",
       "5   Llama-3.2-1B-Instruct            NaN\n",
       "6            Llama-3.2-3B        -0.0558\n",
       "7   Llama-3.2-3B-Instruct            NaN\n",
       "8            Llama-3.1-8B        -0.0512\n",
       "9   Llama-3.1-8B-Instruct            NaN\n",
       "10           Qwen2.5-0.5B         0.0221\n",
       "11  Qwen2.5-0.5B-Instruct            NaN\n",
       "12             Qwen2.5-7B        -0.1371\n",
       "13    Qwen2.5-7B-Instruct            NaN\n",
       "14            Qwen2.5-14B        -0.1398\n",
       "15   Qwen2.5-14B-Instruct            NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_t2_df = pd.DataFrame({\n",
    "    \"model\": models_ids_ordered,\n",
    "    \"instruct_gain\": instruct_gain\n",
    "})\n",
    "gpt_t2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf8e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9e74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
